<p>I have spent the past year thinking a lot about nineteenth century newspapers. This is not an area I had ever really thought about at all, but a coonvergence of circumstances shifted my focus by about 100 years. The first circumstance was a practical one. My advisor, Ryan Cordell, put out a job posting for a research assisstant on his Viral Texts Project. As my advisor, he was well aware of my interests in Literary Journalism and in a number of our early conversations, he brought the nineteenth century into my field of view. When I took the job as his RA, I thought there could be some overlap between that research work and my own interests, but only in the sense that I’d be dealing with periodicals. There ended up being a lot more coherence.</p>

<p>The second circumstance that all but ensured I’d be living in nineteenth century newspapers was precipitated by an almost throw away quote by Norman Sims, early in his <em>True Stories: A Century of Literary Journalism.</em> He writes, “Looking for literary journalism in the nineteenth century seems daunting, but it was incubating and would emerge in the large-circulation urban newspapers at the end of the century” (44). The task is daunting, he writes, because the trail of literary journalism “vanishes into a maze of local publications” (43). For this reason, scholars of literary journalism don’t spend a lot of time in the nineteenth century. I came across this quote while working on my first comprehensive exam, a literary historical look at literary journalsim, and, as a young scholar juiced up on the newly discoverd power of text analsysis, I took Sims’ assertion as a challenge. I will follow that vanishing trail.</p>

<p>When I began my work with the Viral Texts Project, I was tasked with coming up with a computational way to assign genres to our texts. It seems foolish to admit now, a year into the project, that back then I imagined a kind of “one-click” solution. I believed my own elevator pitch explanation of the work, that I could show a few examples of each genre to the computer, and then send it off on its way to find me the rest. It has not been that easy.</p>

<p>In a forthcoming paper that I’ll be presenting at the Keystone DH conference at the University of Pittsburgh later this month I detail my process, and I plan to post that paper here after the conference, so I’ll forego the details of its inner-workings. Instead, here I want to focus on the assumptions that went into my early conception of the project as a self-contained, auto-magical genre classifier. Reflecting on this recently, it occurred to me that I wasn’t operating altogether outside the mode of what I had been learning about DH. That is, I was trying to build a tool.</p>

<p>Through the introduction to DH course I took with Professor Cordell, I was introduced to a number of pre-packaged tools like Omeka, Neatline, and Gephi. Since then, I’ve learned of many others: atlas.ti, Voyant, and the like. These tools are good and all serve a purpose, but even as I was introduced to them, I got the sense that real digital humanists build their own tools. This is what I set out to do.</p>

<p>But the cracks in this idea began to show early. One of the first indications that a ready-made classification tool would never materialize came while reading Ted Underwood’s report <a href="https://figshare.com/articles/Understanding_Genre_in_a_Collection_of_a_Million_Volumes_Interim_Report/1281251">“Understanding Genre in a Collection of a Million Volumes.”</a> He writes that though he’s made his code public, “it definitely is not a tool that could simply be pointed at collections from other libraries, languages, or periods to map them. Our methods can be adapted to other problems. But the process of mapping genres involves too many domain-specific aspects to be packaged as a ‘tool.’” This was a bummer because, had he created such a tool, I most definitely would’ve simply pointed it at my data.</p>

<p>Here, however, Underwood was saying that not only did he not create a tool, such a tool could probably not be created. Starting there, and throughout my own work as my messy, definitely-not-a-tool process began to materialize, I’ve been trying to articulate why this exploratory (and frustrating) method ultimately seemed more meaningful than creating a tool or pointing a pre-made tool at my data. But it wasn’t until I finally got around to reading Kieran Healy’s excellent (and brilliantly titled) essay <a href="https://kieranhealy.org/files/papers/fuck-nuance.pdf">“Fuck Nuance”</a> that I started to formulate an idea as to what seemed problematic about ready made tools.</p>

<p>If you haven’t read Healy’s essay, you should, but by way of summary, the object of Healy’s ire, if somehow it’s not completely obvious, is nuance. Specifically, he takes issue with the way the idea of nuance has been inserted into socialogical theory. He provides a helpful visualization that shows, unmistakably, the rise of nuance in sociological academic journals from the 1980s onward–it’s a steep incline. His thesis is that “demanding more nuance typically obstructs the development of theory that is intellectually interesting, empircally generative, or practically successful.” Any academic from any number of disciplines should recognize, if not the problem, than at least the symptoms of it. We’ve all been to conferences where at least one questioner wishes to push back against the presenter by asking if she’s ever considered this or that theory or author–usually the object of study of the questioner. I had never heard the word “problematize” until I started my PhD program, and now I hear much more often than I care to.</p>

<p>So what does this have to do with tools in DH? My sense is that a ready-made tool is like an overly-nuanced theory, what Healy calls “Actually-Existing Nuance,” which he defines as “the act of making—or the call to make—some bit of theory ‘richer’ or ‘more sophisticated’ by adding complexity to it, usually by way of some additional dimension, level, or aspect, but in the absence of any strong means of disciplining or specifying the relationship between the new elements and the existing ones.” Doesn’t this sound like a DH tool, or, at least, the dream of what a tool could be?</p>

<p>Anyway, this is what I imagined my tool might be, a fully realized genre classifier that takes into account all the complexities, levels, and aspects of whatever genre meant in nineteenth century newspapers. I fell into the trap that many software designers fall into, trying to build something that does everything (open iTunes recently?). But the reality is, a comprehensive tool never materialized, and will never materialize. The concept of genre, it turns out, is mutable over time, space, audience, writer. What actually ended up working is letting the texts define themselves and creating a classifier tailored to the data. It doesn’t work all the time, and requires a lot of paging back and forth across R Script files in R Studio. It doesn’t definitively answer every question about genre that I had when approaching the texts.</p>

<p>In short, lots of things are left out in order to make it work well for  other things. At present, it’s really good at seeing top level genres, but not so great at digging down into them where the differences between, say, a vignette and an advice piece are trickier to discern. But, as Underwood <a href="https://tedunderwood.com/2016/05/29/the-real-problem-with-distant-reading/">writes</a> reflecting on the call for nuance in DH, “It’s okay to simplify the world in order to investigate a specific question.” He continues, “Something will always be left out, but I don’t think distant reading needs to be pushed toward even more complexity and completism.” Franco Moretti had something to say about this as well in his book <a href="https://www.versobooks.com/books/261-graphs-maps-trees"><em>Graphs, Maps, Trees</em></a>, “Problems without a solution are exactly what we need in a field like ours, where we are used to asking only those questions for which we already have an answer.”</p>

<p>It’s okay if a theory or, in this case, a method, raises problems without a solution, or ends up asking more questions than it answers because we shouldn’t be in the business of looking for definitive answers. That’s not how the humanities work. Healy reminds us that “Generative research programs develop theories that aim for a fruitful combination of simplicity and strength” and establishing limits actually allows for the “creative development of new ideas.” And by working to train a classifier to identify some genres in nineteenth century newspapers, I have a lot of new ideas. From my classification efforts, a theory of genre in periodicals of the era is developing. Like the classification experiments that birth it, it won’t be complete, or accountable to all the potential complexities that such a theory might be imagined to contain. It won’t be terribly nuanced. But, with any luck, it will be interesting and generative. It will offer some answers and raise additional questions. It will be complicated, but not over-complicated.</p>

<p>Though, honestly, at this point in my work, I simply hope it will <em>be</em>.</p>

