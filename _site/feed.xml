<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Jonathan D. Fitzgerald</title>
    <description>Digital Human(ist)</description>
    <link>http://jonathandfitzgerald.com/</link>
    <atom:link href="http://jonathandfitzgerald.com/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Mon, 06 Mar 2017 19:56:16 -0500</pubDate>
    <lastBuildDate>Mon, 06 Mar 2017 19:56:16 -0500</lastBuildDate>
    <generator>Jekyll v2.4.0</generator>
    
      <item>
        <title>Computationally Classifying the Vignette Between Fiction and News</title>
        <description>&lt;p&gt;&lt;em&gt;The following is a companion to a paper that Ryan Cordell and I will be presenting at the upcoming ALA 2016 Symposium, The American Short Story: An Expansion of the Genre. Our paper is titled “Vignettes: Micro-Fictions in the Nineteenth Century Newspaper” and in it we discuss the vignette as an essential genre in antebellum American letters, both influential in the development of sentimental fiction and a precursor to the prose writing later styled “literary journalism.” In preparation for the presentation, I’ve been computationally classifying vignettes in an effort to affirm their hybrid status.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;We entered into this project with the notion of vignette as hybrid genre and much of my effort to classify genre within our corpus has been an attempt to bring to the surface some of these harder to classify genres. In an effort, then, to consider the hybrid nature of the vignette, I’ve been attempting to use computational classification methods to place it on a spectrum between news and fiction.&lt;/p&gt;

&lt;!--more--&gt;

&lt;p&gt;I began with three sets of texts—news items culled from our corpus of reprinted nineteenth century newspapers and identified via my classification model, vignettes also derived from that corpus but identified by manually reading a subset of the larger data set, and fictional short stories, which were derived from the &lt;a href=&quot;http://webapp1.dlib.indiana.edu/TEIgeneral/projectinfo.do?brand=wright&quot; target=&quot;_blank&quot;&gt;Wright American Fiction&lt;/a&gt; project out of Indiana University. It was important for us to identify shorter works of fiction from the Wright corpus as we had the sense that vignettes bear a closer resemblance to nineteenth century short stories rather than novels. Thus, from the full set of fiction in the Wright corpus, I manually selected the 200 shortest pieces as indicated by file size. But, even then, the short stories are substantially longer than most news pieces from the Viral Texts corpus, which, in turn are longer than the typical vignette.&lt;/p&gt;

&lt;p&gt;In an effort to ensure that the length of the text wasn’t skewing the results unnecessarily, I needed to do some preprocessing on the Wright texts. I started by removing the metadata about the texts that is included in each file derived from the Wright corpus. This includes information like title, author, publisher, etc. Then, I removed all line breaks so that the text would read as a continuous string. from there I sampled down each text to a random selection of 2000 consecutive characters. The logic behind this was that 200 texts of 2000 characters each would create a corpus that is about equal in size to the corpus of news items from the Viral Texts data. Then, I sampled 200 news items from a larger corpus of over 800 texts. Finally, I combined the fiction and news corpora with the 198 vignettes that I had manually identified.&lt;/p&gt;

&lt;p&gt;The classification method that I’ve been working with uses topics derived from topic modeling a corpus as tokens, as opposed to words, which are more commonly used. The reasons for this are many (I discuss this at greater length in &lt;a href=&quot;http://jonathandfitzgerald.com/blog/2016/07/13/keystone-paper.html&quot; target=&quot;_blank&quot;&gt;this&lt;/a&gt; post), but particularly we’ve found that decreasing the dimensionality in this way leads to a more accurate classifier and, importantly, makes it easier for a human research to understand the computer’s logic. I experimented with different numbers of topics to find a number that would be best suited for classifying texts in my corpus of roughly 600 texts and 50 topics seemed to be the magic number.&lt;/p&gt;

&lt;p&gt;I then use these 50 topics to train the model on what constitutes fiction and what constitutes news. Here are some of the topics:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;states united sthe government state&lt;/li&gt;
  &lt;li&gt;people public made power great &lt;/li&gt;
  &lt;li&gt;york ohio texas ram rammy &lt;/li&gt;
  &lt;li&gt;year total 18 amount fiscal &lt;/li&gt;
  &lt;li&gt;war secretary letter general command &lt;/li&gt;
  &lt;li&gt;lord prayer ou thanksgiving brudder &lt;/li&gt;
  &lt;li&gt;man time good young long &lt;/li&gt;
  &lt;li&gt;life heart room night side &lt;/li&gt;
  &lt;li&gt;father wife home mother poor &lt;/li&gt;
  &lt;li&gt;thy thee lay body thou &lt;/li&gt;
  &lt;li&gt;frank circumstances determined harrington henry &lt;/li&gt;
  &lt;li&gt;farmer pay bill aud merchant&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;If you’re not familiar with topic modeling, the first thing you’ll notice is that these topics are not actually topics in the way you might conceive of that word. That is, it’s not as if these topics tell us what the texts are about. Rather, in topic modeling, topics are groupings of words that are commonly found in close proximity to each other. In fact, the topics you see here are not the full topics, rather they represent the first five words of each topic. &lt;/p&gt;

&lt;p&gt;In my corpus, I identify the genres of news and fiction, but label the vignettes as “unknown” since we ultimately want the classifier to identify these as either fiction or news. That is, we’re not telling the computer that we know that the vignettes are vignettes and asking it to tell us what it thinks they might be. So, when the unknown (vignettes) are removed and a model is created, we find that the classifier is very accurate. It can accurately identify news items and fictional pieces around 90% of the time. This is a check to be sure that the classifier is working the way it is supposed to, and once we see that it is, we can introduce the vignettes as unknowns and let the computer classify these. While the numbers can vary, the classifier most often splits the vignettes between news and fiction within a range of 35/65 and 50/50. That is vignettes are most often misclassified as news, but only just barely. In the majority of my experiments, the split is close to even.&lt;/p&gt;

&lt;p&gt;What we see then, is that a computational classifier that is highly accurate at determining the difference between news and fiction based on topics derived from topic modeling, finds that vignettes are indeed a hybrid of news and fiction. We have run this experiment using a classifier that is seeded with words instead of topics, and found similar results, though the classifier based on words is not as accurate at determining the difference between news and fiction. And, interestingly, the classifier trained with words most often mistakes the vignette for fiction, as opposed to news. This is kind of cool, and I have to look into it more.&lt;/p&gt;

&lt;p&gt;In an effort to ensure that what we are seeing is not just a random sorting of an unknown genre into two known genres, I repeated the experiment using advertisements and poetry derived from the Viral Texts corpus instead of vignettes. Indeed, in these cases the classifier was also effective at guessing what each genre—poetry and ads—was most similar to. That is, poetry is classified as fiction around 80% of the time, and advertisements are classified as news items around 60% to 70% of the time. This last finding might be surprising if you’ve never encountered an advertisement in a nineteenth century newspaper; they are quite prosaic. In fact, they often read similarly to vignettes, which explains why the classifier aligns them more closely with news items.&lt;/p&gt;

&lt;p&gt;We are firm believers in the value of combining the skills of distant reading, which I’ve been describing here, with our more traditional and disciplinary practice of close reading, and so the next step in our process was to read the data created by the classifier to determine if we could discern what exactly makes the computer identify some vignettes as news and others fiction. We can do this first by skimming what you might call our appendix—that is, the topics and their alignments as either fiction or news. When we do this, we find, unsurprisingly, that those topics that include more domestic words like young, good, heart, room, home, mother, and farmer align more closely with fiction. On the other hand, topics that include words like united, states, government, public, fiscal, and war align more closely with news. Vignettes, we’ve found, cover a range of topics and thus can be (mis)classified as either fiction or news.&lt;/p&gt;

&lt;p&gt;From there, however, we need to dive into the texts themselves and read them more closely in an effort to understand what might make the computer classify them as news or fiction. This process is ongoing and we’ll say more about it in the actual paper, which I’m sure will be posted online by either Ryan or me (or both!) shortly after the conference.&lt;/p&gt;

&lt;p&gt;My main goal in posting this here though, in addition to providing supplemental information that won’t be included in the paper we are presenting, is to hopefully get some feedback on the methodology described. Does it seem sound? Any ideas about how I might tweak or refine it? Asking questions at the end of a blog posts always feels a bit like shouting into a black hole, but there you have it.&lt;/p&gt;
</description>
        <pubDate>Mon, 10 Oct 2016 00:00:00 -0400</pubDate>
        <link>http://jonathandfitzgerald.com/blog/2016/10/10/the-viral-vignette.html</link>
        <guid isPermaLink="true">http://jonathandfitzgerald.com/blog/2016/10/10/the-viral-vignette.html</guid>
        
        
        <category>blog</category>
        
      </item>
    
      <item>
        <title>What Made the Front Page in the 19th Century?: Computationally Classifying Genre in &#39;Viral Texts&#39;</title>
        <description>&lt;p&gt;&lt;em&gt;The following is a lightly revised version of the text of a talk I gave at the 2016 Keystone Digital Humanities Conference, held at the University of Pittsburgh. I’m grateful to have had the opportunity to present and for the helpful feedback I received there.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;I’m happy to be with you today on behalf of the &lt;a href=&quot;http://www.viraltexts.org&quot; target=&quot;_blank&quot;&gt;Viral Texts Project&lt;/a&gt;, a project of the &lt;a href=&quot;http://nulab.northeastern.edu&quot; target=&quot;_blank&quot;&gt;NULab for Texts, Maps, and Networks&lt;/a&gt; at Northeastern University. The Viral Texts Project was initiated by Professors Ryan Cordell and David Smith as a way to computationally discover reprinted texts in nineteenth century newspapers.&lt;!--more--&gt;In the nineteenth century, due to lax or non-existent copyright laws, it was very common for newspaper editors to reprint content from other papers, sometimes with slight attribution, but often with no acknowledgment at all. In an effort to identify these viral texts, the team created “algorithms for detecting clusters of reused passages embedded within longer documents in large collections” (Smith et al.). This work is described in previous articles, available from the project’s &lt;a href=&quot;http://www.viraltexts.org&quot; target=&quot;_blank&quot;&gt;website&lt;/a&gt;, and is not my focus here, but the data that I work with is the direct output of these efforts to identify reprints. &lt;/p&gt;

&lt;p&gt;The project was quite successful at identifying reprints—millions of them, in fact—but this led to a new challenge: sorting through those millions of reprints in a meaningful way. A significant goal early on in the genesis of the Viral Texts Project was an effort to create a searchable online archive of reprinted texts that would provide an entry point to the dense corpora of nineteenth century newspapers and allow other scholars to conduct research.&lt;/p&gt;

&lt;p&gt;In a recent article in American Literary History, Cordell identifies the challenge: “When every nineteenth-century newspaper brims with original and reprinted content of all kinds, it is difficult to know where to even begin studying that content” (Cordell). Clustering the texts into groups of reprints is one way to begin, another is to group those texts by genre. &lt;/p&gt;

&lt;p&gt;Easier said than done. I’m not sure if you’ve ever seen a nineteenth century newspaper, so I wanted to show you one. &lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/assets/KeystoneDH - Presentation.005.png&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;/assets/KeystoneDH - Presentation.005.png&quot; alt=&quot;image&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;As a way to make our texts apparent and to visualize our findings on virality, my colleagues and I created a Neatline &lt;a href=&quot;http://loveletter.viraltexts.org&quot; target=&quot;_blank&quot;&gt;exhibit&lt;/a&gt;, which we called “A Stunning Love Letter to Viral Texts.” We annotated a page of The Raftsman’s Journal, a regional paper out of Clearfield, Pennsylvania. We chose this particular paper and this particular issue because it is representative of many nineteenth century newspapers, and also because it contains one of our favorite reprinted texts, here titled “A Stunning Love Letter.” This is online at &lt;a href=&quot;http://loveletter.viraltexts.org&quot; target=&quot;_blank&quot;&gt;loveletter.viraltexts.org&lt;/a&gt; and I’ll invite you to explore it, and if nothing else, to read “Love Letter,” because it’s incredible. But I want to show you this to give you a sense both of what a typical nineteenth century newspaper looks like, and also to illustrate just how viral many of these texts could go. &lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/assets/KeystoneDH - Presentation.009.png&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;/assets/KeystoneDH - Presentation.009.png&quot; alt=&quot;image&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Just about every item you see on this page is a reprint. And take a look at the genres represented—we have poetry, news, fiction, vignettes, lists, jokes, among others. Likewise, the topics represented here are broad; there are pieces about scientific discoveries, etiquette, parenting, religion, and medicine. And, there’s an advertisement.&lt;/p&gt;

&lt;p&gt;Suffice it to say that any researcher interested in determining just what made the front page in the nineteenth century, as my talk is titled, would have a difficult time knowing where to start. This broad array of genre and topics, however, also illustrates the challenges related to classifying these texts in a meaningful way. On the page of a newspaper and to a human reader, those genres seem obvious, but how can we map those human understandings of textual difference across millions of clusters? What happens when machine models can’t match human models? These questions and associated challenges, the ways I attempted to overcome them, and how I learned that overcoming the challenges might not be the point at all, will make up the bulk of my talk today.&lt;/p&gt;

&lt;p&gt;As you’re undoubtedly aware, genre is an incredibly fluid concept. As Christof Schöch notes, “The concept of literary genre is a highly complex one: not only are different genres frequently defined on several, but not necessarily the same levels of description, but consideration of genres as cognitive, social, or scholarly constructs with a rich history further complicate the matter” (1). &lt;/p&gt;

&lt;p&gt;Or, more concisely, according to Ted Underwood, “Centuries of literary scholarship have failed to produce human consensus about genre” (“Understanding Genre” 7). Both Schöch and Underwood are referring to literary genres, and if the ambiguity of genres is a challenge when it comes to differentiating between poetry, prose, and drama and their attendant sub-genres, it is all the more difficult when looking at the broad array represented in nineteenth century newspapers.&lt;/p&gt;

&lt;p&gt;As Underwood points out, computers trained by humans to identify genre will be confounded in the same way that human readers are: Underwood writes of his own project to identify genres in texts from the HathiTrust, “The model was trained, after all, on examples tagged by human beings; the whole point of doing that was to reproduce as much as possible the contours of the boundary that separates genres for us” (“Distant Reading”). &lt;/p&gt;

&lt;p&gt;My methodology draws on the efforts of several other researchers who, in recent years particularly, have taken up the challenge of using computational methods to identify literary genres. Among these are Jonathan Hope and Michael Witmore who worked with genre in Shakespeare’s plays, Lena Hettinger and colleagues, who tested a variety of computational methods to identify genres in German novels, and most significantly, Ted Underwood who, as I noted, has been working with texts from the HathiTrust. &lt;/p&gt;

&lt;p&gt;In my own attempts, I have certainly learned from their efforts, and also very self-consciously tried to infuse my work with the exploratory emphasis that is baked into the work of the Viral Texts Project. That is, as the project developed, my objectives have grown to include not just the creation of an effective classifying method, but also to come to a better understanding of how genres operated in nineteenth century newspapers. I quickly came to understand that I had at my disposal a unique corpus and a means to read that corpus both from a distance and up close. To realize both of these goals, I have been working with Professor Benjamin Schmidt from Northeastern’s history department to develop a classification method that is suitable to the Viral Texts corpus. The method we’re working on uses topics derived from topic modeling a corpus to train a classifier. &lt;/p&gt;

&lt;p&gt;In a blog &lt;a href=&quot;http://bookworm.benschmidt.org/posts/2015-09-14-Classifying_genre.html&quot; target=&quot;_blank&quot;&gt;post&lt;/a&gt; in which he details his experiments with this method on a corpus of 44,000 television episodes, Schmidt acknowledges Underwood’s work and explains his reason for using topics as opposed to words as features. Schmidt writes, “To reduce dimensionality into the model, we have been thinking of using a topic model as the classifiers instead of the tokens. The idea is that classifiers with more than several dozen variables tend to get finicky and hard to interpret, and with more than a few hundred become completely unmanageable.” So there are practical reasons for seeding a classifier with topics as opposed to words or other features, but, again, I chose to work with this method for the ways in which it could serve my exploratory purposes as well. Combining topic modeling and classifying opens up the corpus in a variety of promising ways.&lt;/p&gt;

&lt;p&gt;The first step in creating a classifier to identify genres is to manually assign genres to a selection of texts. That is, I randomly selected 500 clusters from the Viral Texts data, read them, and made decisions regarding their genres. For my first attempt at this, I collaborated with and was guided by Ryan Cordell. Then, after a tremendous update to our database with the inclusion of newspapers from Gale (UK and US), Trove, and APS, in addition to Chronicling America, which is what we started with, I created a new set of hand-tagged genres. After reading over 1,000 clusters, it became clear that the task of assigning genres to the wide array of reprinted material would prove challenging. Poetry, Advertisements, and News were natural choices, but I was left with the question of the various other prose genres that are represented in our corpus. Ideally, I could separate these out into smaller constituents like vignette, sketch, opinion, and advice, but it turns out that the subtle differences between these genres proved confounding for my classifier, as they often do for human readers as well.  Ultimately, I settled on four top-level genres: poetry, news, advertisements, and prose. For each of the clusters tagged prose, I also assigned secondary genres relating both to content and form. I intend to revisit these secondary genres later in an effort to train a classifier to identify distinct genres from among the prose corpus.&lt;/p&gt;

&lt;p&gt;While I hand-tagged 500 clusters, in order to get a more accurate training set, I selected 50 clusters of each genre and reintegrated them into a larger corpus of around 4,000 clusters. This is a small fraction of our entire corpus, which at this point reaches to over a million clusters, but enough to test the classifier without overwhelming my computer. Using the “Mallet” package in R, I topic modeled the clusters, removing stop words. I experimented with the number of topics to generate, ranging from 5 to 500, but ultimately found that a relatively low number—around 10 or 20, and recently 12 seems to be a magic number—worked best. &lt;/p&gt;

&lt;p&gt;Here is the output of one topic model. You can almost guess the genre by looking at the topic names, but you’ll also notice some bad OCR was picked up as well.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/assets/KeystoneDH - Presentation.018.png&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;/assets/KeystoneDH - Presentation.018.png&quot; alt=&quot;image&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I created a matrix of the topics and the probabilities and selected a training set randomly from the matrix. Next, I trained a model using logistic regression and applied the model to each of the four genres. As noted above, one of the benefits of using computational methods for classifying genres is that the results are rendered in terms of probabilities. That is, the output of the classifier indicates the probability that a text belongs to a genre. We can select the genre with the highest probability as a kind of best guess, but it is also useful to see the other probabilities. For now, however, by selecting the best guess I can visualize how the model performed for each genre in the test set. &lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/assets/KeystoneDH - Presentation.020.png&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;/assets/KeystoneDH - Presentation.020.png&quot; alt=&quot;image&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Here is a histogram where the actual genre appears on the Y-axis and the number of clusters assigned to each genre is on the X-axis. The bar is colored to indicate the genre each cluster was assigned by the classifier. You can see that the prose genre, colored purple here, is slightly problematic; it has the lowest accuracy at around 63% and shows up as miscategorized in each of the other genres. Ads and news items are both mistaken for prose. In this case, some poems were misclassified as ads and prose, and the prose genre itself was mistaken for poetry and advertisements. While this was a particularly good result, with an accuracy of 86%, the results differ each time the classifier is run, therefore, to get a sense of the overall accuracy, I run the classifier a number of times and average the results. Typically, after running the classifier 20 times consecutively, I arrive at somewhere between 75-85% overall accuracy. &lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/assets/KeystoneDH - Presentation.021.png&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;/assets/KeystoneDH - Presentation.021.png&quot; alt=&quot;image&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;As this table illustrates, advertisements, poetry, and news are much more accurately classified than prose, but this is owing to the fact that, again, as a combined genre, prose is, at this point, really a kind of “everything else” category.&lt;/p&gt;

&lt;p&gt;I can then apply the model to unknown clusters. I label all clusters without hand-tagged genres as “unknown” and create a data frame that includes just those clusters. I then run the model on that data. The result is every unknown cluster is assigned a genre. I create an additional output that shows me not just the best guess for each cluster, but all of the other guesses as well, arranged in order of probability. &lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/assets/KeystoneDH - Presentation.023.png&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;/assets/KeystoneDH - Presentation.023.png&quot; alt=&quot;image&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Here’s a visualization showing 25 formerly unknown clusters, the genres they were assigned, and the probability that they belong to each genre. In most cases, the decision is split between two genres, and in a couple cases only one genre is shown meaning that the probability that the cluster belonged to any other genre is too low to be relevant. &lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/assets/KeystoneDH - Presentation.024.png&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;/assets/KeystoneDH - Presentation.024.png&quot; alt=&quot;image&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Let’s look at cluster 1010332, which you can see is split just about evenly between prose and news. It turns out this is a historical piece about wages in the 1800s, which appeared in 1885. It notes that “on the Pennsylvania canals, the diggers ate the coarsest diet, were housed in the rudest sheds, and paid $6 month from May to November and $5 a month from November to May.”&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/assets/KeystoneDH - Presentation.026.png&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;/assets/KeystoneDH - Presentation.026.png&quot; alt=&quot;image&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Or check out 1009939, which is classified almost completely as an advertisement. Sure enough. It reads, “If you have coughed and coughed until the lining membrane of your throat and lungs is inflamed, Scott’s Emulsion of Cod-liver Oil will soothe, strengthen and probably cure.” Not very reassuring.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/assets/KeystoneDH - Presentation.028.png&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;/assets/KeystoneDH - Presentation.028.png&quot; alt=&quot;image&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Finally, let’s look at 1012062, which is mostly identified as news, but also poetry. This is part of a longer article about the Knights Templar. The piece is occasioned by the triennial conclave in Washington and occupies a full page in the September 19, 1889 issue of the &lt;em&gt;Jamestown Weekly Alert&lt;/em&gt;. After a brief history of the knighthood, this List of officers elected in 1886 to the Grand Encampment is offered. Is it news? Poetry? You decide. But joking aside, you can see why it might be misclassified as poetry.&lt;/p&gt;

&lt;p&gt;While I’m pleased with these results in the sense that they indicate that the classifier is working well, if I want this data to be useful to other researchers, I want to create a method for verifying the results. To that end, I’ve begun work on a Shiny app that will allow users to check my work. Here’s a screenshot of the work in progress. &lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/assets/KeystoneDH - Presentation.031.png&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;/assets/KeystoneDH - Presentation.031.png&quot; alt=&quot;image&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;As you can see, it serves up the text and asks the viewer if it indeed belongs to the genre it was classified as. If the user selects “No,” a list other possible genres, listed in order of probability, are presented. I hope to have this online soon.&lt;/p&gt;

&lt;p&gt;One of the promises of a project like this is, according to Matthew Jockers, to “lead us not only to a deeper understanding of the genres…but also to clearer definitions of genre itself” (77). The more I worked with these texts and attempted to design the most accurate classifier as I could, this quote kept coming back to me. &lt;/p&gt;

&lt;p&gt;Of course I want a classifier that performs well, as part of the purpose of this project is to make the texts more accessible to researchers who might be interested in one or another particular genre. As a researcher who studies literary journalism, however, the genres I’m most interested in—vignettes and sketches—fall under that broad category of prose that I have not been terribly successful at identifying. On the one hand, this is frustrating. I’d like to be able to click a button and bring forth every text that I might actually be interested in reading. On the other hand, it occurred to me that not only has this work has been revelatory about genres in nineteenth century newspapers, but also about the definitions of genre itself. &lt;/p&gt;

&lt;p&gt;One of my first realizations along these lines came when it occurred to me that I was trying to squeeze newspaper writing from the nineteenth century into the mold of contemporary genres. Aside from poetry, none of the genres look like you’d expect them to look today. Early in my project, before we acquired more data from the latter half of the nineteenth century, it was difficult to even find news in these newspapers. As, I’ve discussed, the wide array of prose genres have little correlation with the kind of writing we expect to find in contemporary newspapers. Even advertisements, written often as narratives or testimonials in the nineteenth century, are unfamiliar. I came to this material with a preset notion of what I would find and until I began to let the data show me what was actually there, I was banging my head against the wall. &lt;/p&gt;

&lt;p&gt;In light of this, my project became to better understand the kinds of writing that were popular in the era on their own terms. And then, if there is any way to carry this forward into my research on literary journalism, it is to begin to theorize how and what these genres became as the nineteenth century came to a close and the twentieth century ushered in a dramatic reshaping of the newspaper landscape in the United States. Clearly, we don’t often find poetry or vignettes or even many sketches in contemporary papers. There just wasn’t any room for this kind of writing in the new so-called objective newspaper at the turn of the century. But prose genres still exist in opinion sections, longer, more narrative reportage, and in advice columns. Further, even by the end of the nineteenth century the kind of writing that would become literary journalism moved into magazines and books where the presence of an author showcasing her subjectivity was more welcome. &lt;/p&gt;

&lt;p&gt;The most interesting and perhaps most generative aspects of this project are not the genres that are easy to classify, but those that are hard. That prose texts are so often misclassified, and that the ambiguity between them is so great, raises a lot of interesting questions. &lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/assets/KeystoneDH - Presentation.038.png&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;/assets/KeystoneDH - Presentation.038.png&quot; alt=&quot;image&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Those pieces that are clearly prose, but misclassified as poetry, for example, are fascinating because what you’re seeing is poetic language employed for expository or narrative purposes. Like the item in the lop left corner of the above image. Or poems that are more narrative in nature sometimes get misclassified as prose. The piece in the lower left-hand corner is a fun example of that. Scripture passages are often classified as poetry, which, depending on the verse, is actually quite accurate. The passage in the top right corner is an example of this. And by looking at not just the primary genre that the classifier assigned to a piece, but also its secondary genre, some really interesting pieces come forward. I’m particularly interested in those that are classified first as prose and second as poetry. Like the one in the bottom right corner, titled “Sadness.” I have so many more examples, too many to share here, but this gives you a sense of the kind of material we’re working with.&lt;/p&gt;

&lt;p&gt;None of this generative interchange between genres was immediately clear to me when I came to the Viral Texts Project with the lofty goal of creating an accurate classifier, but the time spent reading texts and hand-tagging their genres, topic modeling them and studying the output, fine tuning a classifier, and going back and reading the results has, as all good research in the humanities should do, conjured up a new set of questions. &lt;/p&gt;

&lt;p&gt;Paige Morgan, the Digital Humanities Librarian at the University of Miami, recently &lt;a href=&quot;https://twitter.com/paigecmorgan/status/739222187945525248&quot; target=&quot;_blank&quot;&gt;tweeted&lt;/a&gt;, “So much of working with data is just looking at the data,” to which I added, “and reading it.” Computational methods will continue to be helpful in considering these questions, of course, but so too will be delving into the texts and reading. &lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://twitter.com/paigecmorgan/status/739222187945525248&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;/assets/KeystoneDH - Presentation.040.png&quot; alt=&quot;image&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Returning to Matthew Jockers once more; in a paper he co-authored with David Mimno, they write, “The models we present here cannot represent the full meaning of individual books any more than satellite photos can show the details of individual trees. Like the satellite view, however, these macro-, or ‘distant-,’ scale perspectives on literature offer scholars a necessary context for and complement to closer readings” (768). Reading from afar and reading closely—these methods are not at odds, but complimentary and, I’d argue, necessary for this kind of work.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Works Cited&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Cordell, Ryan. “Reprinting, Circulation, and the Network Author in Antebellum Newspapers.” &lt;em&gt;American Literary History&lt;/em&gt; 27, no. 3 (September 1, 2015): 417–45. doi:10.1093/alh/ajv028.&lt;/p&gt;

&lt;p&gt;Jockers, Matthew Lee. &lt;em&gt;Macroanalysis: Digital Methods and Literary History&lt;/em&gt;, 2013.&lt;/p&gt;

&lt;p&gt;Jockers, Matthew L., and David Mimno. “Significant Themes in 19th-Century Literature.” &lt;em&gt;Poetics&lt;/em&gt;, Topic Models and the Cultural Sciences, 41, no. 6 (2013): 750–69. doi:10.1016/j.poetic.2013.08.005.&lt;/p&gt;

&lt;p&gt;Schöch, Christoph. “Topic Modeling Genre: An Exploration of French Classical and Enlightenment Drama.” &lt;em&gt;Digital Humanities Quarterly&lt;/em&gt;, forthcoming.&lt;/p&gt;

&lt;p&gt;Smith, David A., Ryan Cordell, Elizabeth Maddock Dillon, Nick Stramp, and John Wilkerson. “Detecting and Modeling Local Text Reuse.” In &lt;em&gt;Proceedings of the 14th ACM/IEEE-CS Joint Conference on Digital Libraries&lt;/em&gt;, 183–92. IEEE Press, 2014. http://dl.acm.org/citation.cfm?id=2740800.&lt;/p&gt;

&lt;p&gt;Underwood, Ted. “Distant Reading and the Blurry Edges of Genre.” The Stone and the Shell, October 22, 2014. http://tedunderwood.com/2014/10/22/distant-reading-and-the-blurry-edges-of-genre/.&lt;/p&gt;

&lt;p&gt;———. “Understanding Genre in a Collection of a Million Volumes.” University of Illinois, Urbana-Champaign, December 29, 2014.&lt;/p&gt;
</description>
        <pubDate>Wed, 13 Jul 2016 00:00:00 -0400</pubDate>
        <link>http://jonathandfitzgerald.com/blog/2016/07/13/keystone-paper.html</link>
        <guid isPermaLink="true">http://jonathandfitzgerald.com/blog/2016/07/13/keystone-paper.html</guid>
        
        
        <category>blog</category>
        
      </item>
    
      <item>
        <title>Don&#39;t Be a Tool</title>
        <description>&lt;p&gt;When I began my work with the Viral Texts Project, I was tasked with coming up with a computational way to assign genres to our texts. It seems foolish to admit now, a year into the project, that back then I imagined a kind of “one-click” solution. I believed my own elevator pitch explanation of the work, that I could show a few examples of each genre to the computer, and then send it off on its way to find me the rest. It has not been that easy.&lt;!--more--&gt;&lt;/p&gt;

&lt;p&gt;In a forthcoming paper that I’ll be presenting at the &lt;a href=&quot;http://keystonedh.network/2016/&quot; target=&quot;_blank&quot;&gt;Keystone DH&lt;/a&gt; conference at the University of Pittsburgh later this month I explain my process, and I plan to post that paper here after the conference, so I’ll forego the details of its inner-workings. Suffice it to say that the real innovation (with due credit to &lt;a href=&quot;http://bookworm.benschmidt.org/posts/2015-09-14-Classifying_genre.html&quot; target=&quot;_blank&quot;&gt;Ben Schmidt&lt;/a&gt;) is that rather than use words as the classifiers, I’m using topics derived from topic modelling the corpus. &lt;/p&gt;

&lt;p&gt;Here I want to focus on the assumptions that went into my early conception of the project as a self-contained, auto-magical genre classifier. Reflecting on this recently, it occurred to me that I was operating on assumptions common to those who are new to DH. That is, I was trying to build a tool. &lt;/p&gt;

&lt;p&gt;But the cracks in this idea began to show early. One of the first indications that a ready-made classification tool would never materialize came while reading Ted Underwood’s report &lt;a href=&quot;https://figshare.com/articles/Understanding_Genre_in_a_Collection_of_a_Million_Volumes_Interim_Report/1281251&quot; target=&quot;_blank&quot;&gt;“Understanding Genre in a Collection of a Million Volumes.”&lt;/a&gt; He writes that though he’s made his code public, “it definitely is not a tool that could simply be pointed at collections from other libraries, languages, or periods to map them. Our methods can be adapted to other problems. But the process of mapping genres involves too many domain-specific aspects to be packaged as a ‘tool.’” This was a bummer because, had he created such a tool, I most definitely would’ve simply pointed it at my data.&lt;/p&gt;

&lt;p&gt;Here, however, Underwood was saying that not only did he not create a tool, such a tool could probably not be created. Starting there, and throughout my own work as my messy, definitely-not-a-tool process began to materialize, I’ve been trying to articulate why this exploratory (and frustrating) method ultimately seemed more meaningful than creating a tool or pointing a pre-made tool at my data. But it wasn’t until I finally got around to reading Kieran Healy’s excellent (and brilliantly titled) essay &lt;a href=&quot;https://kieranhealy.org/files/papers/fuck-nuance.pdf&quot; target=&quot;_blank&quot;&gt;“Fuck Nuance”&lt;/a&gt; that I started to formulate an idea as to what seemed problematic about ready-made tools.&lt;/p&gt;

&lt;p&gt;If you haven’t read Healy’s essay, you should, but by way of summary, the object of Healy’s ire, if somehow it’s not completely obvious, is nuance. Specifically, he takes issue with the way the idea of nuance has been forcefully inserted into sociological theory. He provides a helpful visualization that shows, unmistakably, the rise of nuance in sociological academic journals from the 1980s onward–it’s a steep incline. His thesis is that “demanding more nuance typically obstructs the development of theory that is intellectually interesting, empirically generative, or practically successful.” Any academic from any number of disciplines should recognize, if not the problem, than at least the symptoms of it. We’ve all been to conferences where at least one questioner wishes to push back against the presenter by asking if she’s ever considered this or that theory or author–usually the object of study of the questioner. I had never heard the word “problematize” until I started my PhD program, and now I hear it far more often than I care to.&lt;/p&gt;

&lt;p&gt;So what does this have to do with tools in DH? My sense is that a ready-made tool is like an overly-nuanced theory, imbued with what Healy calls “Actually-Existing Nuance,” which he defines as “the act of making—or the call to make—some bit of theory ‘richer’ or ‘more sophisticated’ by adding complexity to it, usually by way of some additional dimension, level, or aspect, but in the absence of any strong means of disciplining or specifying the relationship between the new elements and the existing ones.” &lt;/p&gt;

&lt;p&gt;This is kind of what I imagined my tool might be, a fully realized genre classifier that takes into account all the complexities, levels, and aspects of whatever genre meant in nineteenth century newspapers. I fell into the trap that many software developers fall into, trying to build something that does everything (open iTunes recently?). But the reality is, a comprehensive tool never materialized, and will never materialize. The concept of genre, it turns out, is mutable over time, space, audience, writer. What actually ended up working is letting the texts define themselves and creating a model tailored to the data. Even the idea to use topics rather than tokens as classifiers is an effort to reduce dimensionality in the model, to do without nuance. It doesn’t work all the time, and requires a lot of paging back and forth across R Script files in R Studio. It doesn’t definitively answer every question about genre that I had when approaching the texts. &lt;/p&gt;

&lt;p&gt;In short, lots of things are left out in order to make my model work well for  other things. At present, it’s really good at seeing top-level genres, but not so great at digging down into them where the differences between, say, a vignette and an advice piece are trickier to discern. But, as Underwood &lt;a href=&quot;https://tedunderwood.com/2016/05/29/the-real-problem-with-distant-reading/&quot; target=&quot;_blank&quot;&gt;writes&lt;/a&gt; reflecting on the call for nuance in DH, “It’s okay to simplify the world in order to investigate a specific question.” He continues, “Something will always be left out, but I don’t think distant reading needs to be pushed toward even more complexity and completism.” Franco Moretti had something to say about this as well in his book &lt;a href=&quot;https://www.versobooks.com/books/261-graphs-maps-trees&quot; target=&quot;_blank&quot;&gt;&lt;em&gt;Graphs, Maps, Trees&lt;/em&gt;&lt;/a&gt;, “Problems without a solution are exactly what we need in a field like ours, where we are used to asking only those questions for which we already have an answer.”&lt;/p&gt;

&lt;p&gt;It’s okay if a theory or, in this case, a model, raises problems without a solution, or ends up asking more questions than it answers; we aren’t in the business of looking for definitive answers. That’s not how the humanities work. Julia Flanders &lt;a href=&quot;http://digitalhumanities.org/dhq/vol/3/3/000055/000055.html&quot; target=&quot;_blank&quot;&gt;reminds&lt;/a&gt; us to value “Methods and tools that combine what has been gained in power and scale with a real measure of scholarly effort and engagement.” She continues, “the intellectual outcomes will not be judged by their power or speed, but by the same criteria used in humanities scholarship all along: does it make us think? does it make us keep thinking?”&lt;/p&gt;

&lt;p&gt;Early in my process I was driven to create a tool with power and speed; eventually, I remembered to stop and think. From my classification efforts, a theory of genre in periodicals of the era is developing. Like the classification experiments that birth it, it won’t be complete, or accountable to all the potential complexities that such a theory might be imagined to contain. It won’t be terribly nuanced. But, with any luck, it will be interesting and generative. It will offer some answers and raise additional questions. It will be complicated, but not over-complicated.&lt;/p&gt;

&lt;p&gt;Though, honestly, at this point in my work, I just hope it won’t be a tool.&lt;/p&gt;
</description>
        <pubDate>Fri, 10 Jun 2016 00:00:00 -0400</pubDate>
        <link>http://jonathandfitzgerald.com/blog/2016/06/10/genres-and-nuance.html</link>
        <guid isPermaLink="true">http://jonathandfitzgerald.com/blog/2016/06/10/genres-and-nuance.html</guid>
        
        
        <category>blog</category>
        
      </item>
    
      <item>
        <title>A “Stunning” Love Letter to Viral Texts: A “sublimely splendiferous” foray into nineteenth century newspapers</title>
        <description>&lt;p&gt;On this day, 147 years ago, Volume 15, Number 10 of &lt;i&gt;The Raftsman’s Journal&lt;/i&gt; was published in Clearfield, Pennsylvania. Among the stories featured on its front page were a short work of fiction called “The Dashford Tragedy”; a vignette titled “Who Ate Roger Williams”; a poem, “Marjorie’s Almanac”; and “A ‘stunning’ Love Letter,” described by the editor—hyperbolically, though not inaccurately—as “sublimely ‘spendiferous.’” More on the love letter in a moment.&lt;/p&gt;
&lt;!--more--&gt;
&lt;p&gt;There is nothing particularly remarkable about the November 4, 1868, issue of &lt;i&gt;The Raftsman’s Journal.&lt;/i&gt; Like most newspapers, it would have been read and then discarded by those within the reach of its circulation, while its editors would have mailed a copy to other newspaper editors around the country, which is, after all, how the common practice of reprinting&amp;nbsp;articles from other periodicals&amp;nbsp;was done&amp;nbsp;in the 19th century. And yet, that it is in many ways a typical 19th century American newspaper is one of the reasons my colleagues and I on the Viral Texts Project chose it to use as an entry point for the public to the data we are immersed in.&lt;/p&gt;
&lt;p&gt;The&amp;nbsp;&lt;a href=&quot;http://www.viraltexts.org&quot;&gt;Viral Texts Project&lt;/a&gt;, led by NULab Core Faculty members&amp;nbsp;Ryan Cordell and David A. Smith, is concerned with mapping networks of reprinting in 19th century newspapers. Or, as the name of the project suggests, we’re looking for texts that went viral in the 1800s. To this end, we work with a lot of data in the form of clusters of reprinted stories, poems, lists, recipes, jokes, religious material, and articles from the era. A perennial problem for us has been how to make this data accessible to those outside of our project.&lt;/p&gt;
&lt;p&gt;We have created some large-scale visualizations such as &lt;a href=&quot;http://viraltexts.org/visualizations/&quot;&gt;maps&lt;/a&gt; of reprints over space and &lt;a href=&quot;http://networks.viraltexts.org&quot;&gt;network graphs&lt;/a&gt; of reprints, but we hadn’t created any intensely local visualization of the data for the purpose of providing a narrow entry point into the larger corpus.&lt;/p&gt;
&lt;p&gt;That is until, while hand-tagging a subset of clusters by genre, we came across the “sublimely ‘splendiferous’” love letter. This is really, for a lot of reasons, a remarkable piece. It is a satirical letter offered, in various iterations, as a model for a young man trying to impress a woman. It includes such over-the-top metaphors as: “Your forehead is smoothar [sic] than the elbow of an old coat” and “Away from you I am as melancholy as a sick rat.”&lt;/p&gt;
&lt;p&gt;Professor Cordell, my fellow graduate researcher Abby Mullen, and I decided to use the love letter to create a visual introduction to the Viral Texts data—a light-hearted entry point into the dense data we’d been studying—using &lt;a href=&quot;http://neatline.org/&quot;&gt;Neatline&lt;/a&gt;. Bethany Nowviskie, in a blog post titled “&lt;a href=&quot;http://nowviskie.org/2014/neatline-and-visualization-as-interpretation/&quot;&gt;Neatline &amp;amp; Visualization as Interpretation&lt;/a&gt;,” describes Neatline as “a digital storytelling tool” that “lets you make hand-crafted, interactive stories as interpretive expressions of a single document or a whole archival or cultural heritage collection.”&lt;/p&gt;
&lt;p&gt;Using our online database, we searched for other reprints of the love letter and found that it was printed in more than&amp;nbsp;&lt;a href=&quot;http://viraltexts.northeastern.edu/clusters/search?q=%22like%20a%20churn%20dasher%22&amp;amp;r=2,150&amp;amp;full=1&quot;&gt;60 newspapers&lt;/a&gt; around the U.S. After looking at several, we chose the version found in &lt;i&gt;The Raftsman’s Journal &lt;/i&gt;as our base image—and conceptual starting point—for a number of reasons, including the clarity of the image &lt;a href=&quot;http://chroniclingamerica.loc.gov/lccn/sn85054616/1868-11-04/ed-1/seq-1/&quot;&gt;from Chronicling America&lt;/a&gt; and the variety of content printed on the front page. While we wanted to showcase the diversity of the genres available in our data, we didn’t expect to find that nearly every item on the page appeared at least once elsewhere in the corpus. Most of the time when working with our data, we’re looking at spreadsheets or running queries into large data frames, but working at the level of the individual page and tracing the connections out from there allowed us to see a quality of the data that the spreadsheets do not reveal.&lt;/p&gt;
&lt;p&gt;In order to really show just how thickly reprints dominated this page, we had to literally draw boxes around each article and then delve into our data to annotate each item. In “Neatline &amp;amp; Visualization as Interpretation,” Nowviskie writes, “Neatline sees visualization itself as part of the interpretive process of humanities scholarship – not as an algorithmically-generated, push-button result or a macro-view for distant reading – but as something created minutely, manually, and iteratively, to draw our attention to small things and unfold it there.”&lt;/p&gt;
&lt;p&gt;This is precisely what we hoped to do with with the love letter. It is a small thing, not even one full column on the front page of a long-defunct newspaper from the middle of Pennsylvania, but it folds out to&amp;nbsp;the vast corpus of 19th century newspaper texts. We don’t make any claim toward the completeness of the annotations, and the dataset that we link to is not our entire&amp;nbsp;corpus, as it continues to grow, but hand-annotating this data—“minutely, manually, and iteratively”—was a productive interpretive process that allows us to look at this “small data in a big data world,” as Nowviskie puts it.&lt;/p&gt;
&lt;p&gt;Of course, in addition to all of this, it was a fun project. One that, as Julius Epaminondas Muggins—our fictional letter writer—says of his love, made our hearts flop “up and down like a churn dasher” and caused “sensations of unutterable joy [to] creep over [them] like young goats over a stable roof.” We hope that you’ll find this interpretive act similarly informative, enlightening, and, of course, “sublimely splendiferous.”&lt;/p&gt;
&lt;p&gt;Check out “A ‘Stunning’ Love Letter to Viral Texts”&amp;nbsp;&lt;a href=&quot;http://loveletter.viraltexts.org&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p style=&quot;font-weight:bold;&quot;&gt;Originally published at &lt;a href=&quot;http://www.northeastern.edu/nulab/a-stunning-love-letter-to-viral-texts/&quot; target=&quot;_blank&quot;&gt;nulab.neu.edu&lt;/a&gt;.&lt;/p&gt;</description>
        <pubDate>Wed, 04 Nov 2015 00:00:00 -0500</pubDate>
        <link>http://jonathandfitzgerald.com/blog/2015/11/04/a-stunning-love-letter.html</link>
        <guid isPermaLink="true">http://jonathandfitzgerald.com/blog/2015/11/04/a-stunning-love-letter.html</guid>
        
        
        <category>blog</category>
        
      </item>
    
      <item>
        <title>Acting In and On Space and Place: A Reflection on Dr. Angel David Nieves’ Recent NULab Lecture</title>
        <description>&lt;p&gt;“Black matters are spatial matters,” writes Katherine McKittrick in the introduction to her 2006 &lt;a href=&quot;https://www.upress.umn.edu/book-division/books/demonic-grounds&quot;&gt;book&lt;/a&gt; &lt;i&gt;Demonic Grounds: Black Women and the Cartographies of Struggle&lt;/i&gt;. McKittrick acknowledges that all people “produce, know, and negotiate space,” but “geographies in the diaspora are accentuated by racist paradigms of the past and their ongoing hierarchical patterns.” Her project, she writes, is not to provide “a corrective story” or to embark on any kind of discovery, but rather to “suggest that space and place give black lives meaning in a world that has, for the most part, incorrectly deemed black populations and their attendant geographies as ‘ungeographic’ and/or philosophically undeveloped.”&lt;/p&gt;
&lt;!--more--&gt;
&lt;p&gt;&lt;img class=&quot;alignleft wp-image-1164 size-medium&quot; src=&quot;http://www.northeastern.edu/nulab/wp-content/uploads/2015/10/soweto763d-300x185.jpg&quot; alt=&quot;soweto763d&quot; width=&quot;300&quot; height=&quot;185&quot;/&gt;A similar task has been taken up by&amp;nbsp;&lt;a href=&quot;http://www.angeldavidnieves.com/&quot;&gt;Dr. Angel David Nieves&lt;/a&gt;, who recently visited Northeastern University and the NULab to meet students and faculty and to offer a lecture titled “Critical Engagements with Race, Memory, and the Built Environment: A Primer for the Digital Humanities.” Dr. Nieves is Associate Professor of Africana Studies, Director of the American Studies Program, and co-director of the Digital Humanities Initiative at Hamilton College in Clinton, New York.&lt;/p&gt;
&lt;p&gt;The lecture, which was well attended by students and faculty from across a broad spectrum of departments, focused on Dr. Nieves’ in-process project&amp;nbsp;&lt;a href=&quot;http://soweto76archive.org/3d/&quot;&gt;Soweto ’76 3D&lt;/a&gt;, which grew out of an earlier&amp;nbsp;&lt;a href=&quot;http://www.soweto76archive.org/&quot;&gt;exploration&lt;/a&gt;&amp;nbsp;into the history of Soweto (a cluster of townships south-west of Johannesburg where black laborers were relocated before and during Apartheid) using digital humanities tools. Soweto ’76 3D explores connections between metaphorical and physical places of struggle and aims to provide a kind of spatial microhistory in an effort to illuminate the relationship between resistance and the spatial geography on&amp;nbsp;which that resistance is acted out.&lt;/p&gt;
&lt;p&gt;Dr. Nieves offered a preview of the project, which included some developments and features that are currently not available on the public version of the archive (&lt;a href=&quot;http://www.soweto76archive.org/&quot;&gt;www.soweto76archive.org&lt;/a&gt;). When completed, Soweto ’76 3D will have a kind of video game interface in which the user will be able to interact with the people and places by acting as characters from the time period as well as through a social element that will bring together “local Soweto residents, national and international scholars, and former students who actually experienced the events” of the June 16, 1976 uprising, according to Dr. Nieves’ website.&lt;/p&gt;
&lt;p&gt;In the Q&amp;amp;A after Dr. Nieves talk, he noted that the landscapes he is modeling were constantly modified by the people living in them and became mechanisms by which black South Africans fought and resisted oppression.&lt;/p&gt;
&lt;p&gt;It occurs to me that the ways in which the landscapes were modified, including the differences between official plans for the area and the lived experiences of South Africans in these spaces, may prove to be the most enlightening aspect of the project. It might also prove to be the most challenging to showcase. That is, one of the goals of this project is viewing Soweto as a non-static space open to various interpretations, which aligns with McKittrick’s notion, from her introduction to&amp;nbsp;&lt;i&gt;Demonic Grounds,&lt;/i&gt;&amp;nbsp;that in the effort to forge “a conceptual connection between material or concrete spaces, language, and subjectivity, openings are made possible for envisioning an interpretive world, rather than a transparent and knowable world.”&lt;/p&gt;
&lt;p&gt;A challenge in a project like Soweto ’76 3D, which Dr. Nieves recognizes in his assertion that landscapes are constantly modified, is to not let the virtual world that is created become just another “transparent and knowable world.” But this is also&amp;nbsp;one of the benefits of Soweto ’76 3D—the technology available affords its creators the opportunity to show the ways in which a space is changed by its inhabitants, and even to allow its virtual inhabitants to have some affect on the space.&lt;/p&gt;
&lt;p&gt;I look forward to following Dr. Nieves’ project as it develops, and, hopefully, to one day have the opportunity to experience his “interpretive world” for myself—becoming an actant in the space rather than a passive observer.&lt;/p&gt;
&lt;p&gt;If you’d like to follow the project’s progress, head over to&amp;nbsp;&lt;a href=&quot;http://www.soweto76archive.org&quot;&gt;www.soweto76archive.org&lt;/a&gt;&amp;nbsp;and follow Dr. Nieves on&amp;nbsp;&lt;a href=&quot;https://twitter.com/angeldnieves&quot;&gt;Twitter&lt;/a&gt;.&lt;/p&gt;
&lt;p style=&quot;font-weight:bold;&quot;&gt;Originally published at &lt;a href=&quot;http://www.northeastern.edu/nulab/acting-in-and-on-space-and-place-a-reflection-on-dr-angel-david-nieves-recent-nulab-lecture/&quot; target=&quot;_blank&quot;&gt;nulab.neu.edu&lt;/a&gt;.&lt;/p&gt;</description>
        <pubDate>Wed, 21 Oct 2015 00:00:00 -0400</pubDate>
        <link>http://jonathandfitzgerald.com/blog/2015/10/21/acting-on-space-and-place.html</link>
        <guid isPermaLink="true">http://jonathandfitzgerald.com/blog/2015/10/21/acting-on-space-and-place.html</guid>
        
        
        <category>blog</category>
        
      </item>
    
      <item>
        <title>The InstaEssay Archive: Past, Present, and Future</title>
        <description>&lt;p&gt;&lt;em&gt;Note: I will be presenting a more formalized version of this work at the Keystone DH conference at Penn this summer, and the purpose of this post is to show a work in progress. Already in the hours since posting it, I&#39;ve heard from some of the authors discussed here that there may be some problems with my data and/or analysis. Most glaringly, an unescaped character is breaking my Instagram scraper for the user @ruddyroye and thus his full body of work is not represented. I will be correcting this ASAP, and I&#39;m grateful to Ruddy Roye for pointing this out. &lt;/em&gt;&lt;/p&gt;
&lt;!--more--&gt;
&lt;p&gt;&lt;b&gt;1. Prologue: What is an InstaEssay?&lt;/b&gt;&lt;/p&gt;
&lt;p&gt;Beginning in April, 2014, a number of writers began to utilize Instagram beyond its common use as an application that enables the creation, stylizing, and sharing of personal photographs to a particular group of friends, acquaintances, and followers, and rather as a journalistic tool. In particular, writers like Jeff Sharlet and Neil Shea have paired their photos with short narratives, constrained to 2200 characters by Instagram’s caption limit. The effect is similar to that of “Flash Fiction”—short, impactful self-contained stories—except that these stories are true and paired with a photograph of the subject. While the genre is called by a number of different names, most people refer to the form as “InstaEssays.”&lt;/p&gt;
&lt;p&gt;A variety of media outlets have begun to pick up on this trend and locate it within the scope of literary journalism. The website “&lt;a href=&quot;http://longreads.com&quot;&gt;Longreads&lt;/a&gt;,” which typically collects and syndicates long form reporting and essays, &lt;a href=&quot;http://blog.longreads.com/2014/10/01/nightshift-excerpts-from-an-instagram-essay/&quot;&gt;collected&lt;/a&gt; Sharlet’s #nightshift series and included an essay by Sharlet on the work. There he refers to InstaEssays as “Snapshot Journalism” and locates its lineage within the frame of comic books, which use words and pictures, and snapshots, which, he points out anyone can take. Sharlet concludes his essay by noting, “It’s not the news. It’s not journalism in any conventional sense. It’s, Look at this! It’s, I saw these people, and I wanted you to see them, too.”&lt;/p&gt;
&lt;p&gt;I wrote a blog post titled “Instagram Essay Introduction” in November, 2014, and included several embedded examples of the genre. It is available &lt;a href=&quot;http://www.jonathandfitzgerald.com/instagram-essay-presentation/&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;2. Getting Started: Launching The InstaEssay Archive with Omeka&lt;/b&gt;&lt;/p&gt;
&lt;p&gt;In the fall of 2014, my first semester as a PhD student in the English department at Northeastern University, I enrolled in Professor Ryan Cordell’s introduction to Digital Humanities course titled Texts, Maps, and Networks. The course included a reading component in which we were exposed to some fundamental texts in the field of Digital Humanities, but it also had a practice component in which we had the opportunity to become acquainted with some of the most commonly used DH tools. Among the tools we were introduced to were TEI, Gephi, Omeka, and Neatline. For the Omeka lesson, we were encouraged to think of some data we might want to compile into an archive.&lt;/p&gt;
&lt;p&gt;Around that same time, I became aware of the emerging genre of InstaEssays. It seemed to me at the time that InstaEssays would make for the perfect data to be archived as part of my introduction to Omeka for a number of reasons. First, the amount of data that had been produced up to that point was still rather minimal, and thus manageable. Next, though Instagram appears to be a relatively stable social media platform, there is always the risk that either the platform itself would disappear or that the users who are using it to create InstaEssays might close down their accounts and take their posts with them. Finally, Instagram is built in such a way that it privileges its mobile app over its website. That is, unless you’re using the app on the phone, the ability to easily browse and, especially, search the platform are severely limited.&lt;/p&gt;
&lt;p&gt;With these motivations—as well as the need to produce a functioning Omeka archive in fulfillment of the assignment—I set up an Omeka site and manually added a few InstaEssay posts. This was the first iteration of what would become The InstaEssay Archive. Even beginning with such a small data set, a number of problems presented themselves. Omeka uses the Dublin Core standard for metadata, which is quite comprehensive, but it was necessary to determine how to categorize the metadata related to the Instagram posts. For example, each item in the Omeka archive needs a title, but Instagram posts do not have titles. Additionally, there is a limited set of categories from which to choose when adding an item to Omeka. Are InstaEssays texts or images primarily? It was clear that in my role as archivist I was going to have to make a number of decisions about the nature of my data.&lt;/p&gt;
&lt;p&gt;Beyond these considerations awaited the biggest challenge: how to efficiently gather the data to add to the collection. While my initial demo site included only five items, when I decided to continue this work and expand it into my final project for Professor Cordell&#39;s course, I needed a way to determine which posts should be included and then collect hundreds of Instagram posts into a database that I could upload to Omeka using its CSV import functionality. The problem of what posts to include has remained a constant throughout the development of this project, but at the beginning I simply hand selected posts by users that I knew to be working within the form. I assembled a number of different available web-based tools to assist in the process of gathering Instagram posts and, when these tools reached their limitations, I simply resorted to manual data entry.&lt;/p&gt;
&lt;p&gt;The first version of the InstaEssay Archive went live at &lt;a href=&quot;http://www.instaessayarchive.org&quot;&gt;www.instaessayarchive.org&lt;/a&gt; on December 11, 2014. It was far from perfect, but it was a start. In addition to the collection of items, I also created a map of those posts that included geographic data and a timeline using Neatline, as well as a very basic network visualization—created with Gephi—showing the relationships on Instagram of the writers whose work I included in the archive.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;/Screen-Shot-2015-05-19-at-1.46.34-PM.png&quot;&gt;&lt;img class=&quot; size-full wp-image-438 aligncenter&quot; src=&quot;/assets/Screen-Shot-2015-05-19-at-1.46.34-PM.png&quot; alt=&quot;Screen Shot 2015-05-19 at 1.46.34 PM&quot; width=&quot;465&quot; height=&quot;440&quot; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;In the month that followed I only updated the site once, including new posts I had gathered in that time, but the process was, again, laborious and imperfect. I might have left this project to languish had it not been for a new course, which I began in the spring semester of 2015, Professor Benjamin Schmidt’s Humanities Data Analysis course. If Professor Cordell’s Texts, Maps, and Networks was a kind of introduction to DH, Professor Schmidt’s class was the next progressive step. It was in that course that I learned a new set of tools for working with data, which ultimately revived the InstaEssay Archive project. The narrative of what I learned in that course and the new tools I applied will make up the bulk of this essay. The problems I set out to solve include a method for more efficiently collecting InstaEssays, a means to find additional InstaEssays for inclusion from the vast sea of media that is Instagram, and assembling a set of tools for meaningful analysis of the data.&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;&lt;a href=&quot;/Screen-Shot-2015-05-19-at-1.46.45-PM.png&quot;&gt;&lt;img class=&quot;alignnone size-full wp-image-437&quot; src=&quot;/assets/Screen-Shot-2015-05-19-at-1.46.45-PM.png&quot; alt=&quot;Screen Shot 2015-05-19 at 1.46.45 PM&quot; width=&quot;443&quot; height=&quot;473&quot; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;b&gt;3. Learning R: Archiving and Analyzing&lt;/b&gt;&lt;/p&gt;
&lt;p&gt;The first several weeks of Professor Schmidt’s course were dedicated to familiarizing myself with R, a programming language with which I had no previous experience, and R Studio a software package designed for coding in R. In those initial lessons, the class learned how to work with regular expressions, clean data, create visualizations, read in texts, and perform basic non-quantitive digital analysis. Over spring break, we were tasked with finding our own data to work with in R. By this point in the semester I saw the great opportunity that working in R would provide for further exploring my InstaEssay data. Beyond simply archiving, which, I’ve tried to make clear was already wrought with its own challenges, I now had the opportunity to simultaneously perform analysis on the data as I gathered it. This distinguishes the project from many other archival projects, which seek to assemble data for scholars to work on at a later date, as well as other data analysis projects, which typically work with data that has already been compiled and made available for research.&lt;/p&gt;
&lt;p&gt;The first task I faced was finding a more efficient way to collect data from Instagram as I had become keenly aware that the data I had gathered for the initial iteration of The InstaEssay Archive was deeply flawed. For example, one of the writers I included in that first version informed me that I had mismatched her photos with another writers’ captions.&lt;/p&gt;
&lt;p&gt;Early in the semester in Humanities Data Analsysis, we discussed possible means of gathering data and one of the options presented was scraping data from the internet where that was technically possible and legally permissable. Over spring break I began to research how I might accomplish this using R. I came across a blog post by Julian Hill at &lt;a href=&quot;http://r-bloggers.com&quot;&gt;r-bloggers.com&lt;/a&gt; titled “&lt;a href=&quot;http://www.r-bloggers.com/analyze-instagram-with-r/&quot;&gt;Analyze Instagram with R&lt;/a&gt;” in which the process of registering an application with Instagram’s API, getting post data for a particular Instagram user, and performing some initial analysis and visualization of that data is detailed. I followed Hill’s directions to register the InstaEssay Archive with Instagram, and, after a few missteps, was able to connect R Studio to Instagram and begin pulling down data.&lt;/p&gt;
&lt;p&gt;Instagram lists 20 posts per page on its website and uses Javascript to dynamically load the following page and next 20 posts. This means that when requesting posts from a user’s page, only 20 are downloaded at once. However, Instagram’s API also provides pagination information as part of the data. With Professor Schmidt’s help, I was able to modify Hill’s code by creating a function that would request the following page in a loop until no further pages were available, as indicated by the absence of data in the Next URL field.&lt;/p&gt;
&lt;p&gt;I ran this function individually on each Instagram user from my initial set—as well as a few others that I had become aware of in the months since I launched the archive—and in a matter of seconds was able to gather every post they had ever created with the assurance that the information was accurate as it came directly from the source. Before I even began to perform analysis on the data, I replaced all of the items in my Omeka site with the new data. This, in itself was a vast improvement afforded me by working with R. From there, however, the real fun began as I turned my attention to analysis.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;4. Analyzing InstaEssays: Initial Questions&lt;/b&gt;&lt;/p&gt;
&lt;p&gt;Once I had collected this initial data, there were a number of goals that seemed within my reach. These goals aligned with some of the initials problems I encountered in setting up the archive. For example, I wanted the archive to not just be a collection of InstaEssays, but in some way to also tell the story of how the genre developed and continued to grow. In my first iteration of the InstaEssay Archive, I attempted to accomplish this by creating the timeline and map using Neatline. Analyzing the data in R, however, opened up new ways to tell this story.&lt;/p&gt;
&lt;p&gt;Additionally, one of the greatest challenges from the outset was how to find new posts to include in the archive. I began with a set of users who I knew were working in the genre, but I knew that there were others doing similar work. One possibility for finding these new writers that never worked as well as I’d hoped was searching by hashtags that are often used in InstaEssays. However, to date there is not one hashtag in common use. Rather, there are several that writers use but that are also used by other Instagram users not working in this genre. Finally, I was interested in determining whether there were certain stylistic conventions associated with the genre.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;5. Telling the Story: Over Time, Space, and Popularity&lt;/b&gt;&lt;/p&gt;
&lt;p&gt;There are a few ways to visualize the story of the birth of the genre of InstaEssays. The first, is to show the number of posts over time, as in figure 3, which ranges from April, 2014, to March, 2015.&lt;/p&gt;
&lt;p&gt;To create this visualization, I combined the posts I had gathered from the users I identified as consistently working within the genre and then grouped them by month and year. I performed a count on the number of posts per month and then plotted that over time. According to this graph, the genre was born in April, 2014, when nearly 80 posts were published. As it turns out, these were almost all created by Neil Shea, who was on assignment for &lt;i&gt;National Geographic&lt;/i&gt; in East Africa when he began writing in the genre. (Correction: I had initially surmised that Shea launched the genre, but he informed me that Ruddy Roye had been working in this format before him.) Another interesting thing that this graph shows is that InstaEssays peaked in number in October, 2014. By this point, Jeff Sharlet had begun posting and was gaining media attention for his work. Coincidentally, this is also the month in which I began the process of archiving the genre.&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;&lt;a href=&quot;/Screen-Shot-2015-05-19-at-1.47.01-PM.png&quot;&gt;&lt;img class=&quot;alignnone size-full wp-image-436&quot; src=&quot;/assets/Screen-Shot-2015-05-19-at-1.47.01-PM.png&quot; alt=&quot;Screen Shot 2015-05-19 at 1.47.01 PM&quot; width=&quot;702&quot; height=&quot;490&quot; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;I also experimented with showing the usage of particular hashtags associated with the genre over time, although, as I noted there is not at this point a common hashtag that all InstaEssay writers use, nor is there a hashtag used only by these writers. Thus, while the line in figure 4, which shows posts tagged #picturesandwords over time, corresponds in some ways with the one in figure 3—it too reaches its zenith in October, 2014—it includes more than just InstaEssays, and thus dates back to before April, 2014.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;/Screen-Shot-2015-05-19-at-1.47.11-PM.png&quot;&gt;&lt;img class=&quot; size-full wp-image-435 aligncenter&quot; src=&quot;/assets/Screen-Shot-2015-05-19-at-1.47.11-PM.png&quot; alt=&quot;Screen Shot 2015-05-19 at 1.47.11 PM&quot; width=&quot;708&quot; height=&quot;351&quot; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Another interesting way to visualize the spread of InstaEssays is to use the geographical data that some—but not all—Instagram users include in their posts. I initially accomplished this in the first iteration of the archive using Neatline, which is helpful in that the map it creates is interactive—users can hover over a point on the map and see the post it represents. But I wanted to recreate this using the cleaner data in R. Another benefit of mapping the posts in R is that I could set the size of each point to represent the number of posts assigned to a particular location. The map that resulted from these initial attempts is not as attractive as the map created in Neatline—though at present this represents a limitation in my map making skills using R as opposed to an inherent limitation in R.&lt;/p&gt;
&lt;p&gt;Thought it’s difficult to see in figure 5, the three users in my database that tag their Instagram posts with geographic data are Jeff Sharlet (jeffsharlet), Neil Shea (neilshea13), and Ruddy Roye (ruddyroye). Most of Sharlet’s posts originate in the northeastern United States, near his home. Though, he also has written some posts from the Midwest as well as from Russia. Neil Shea also writes from the Northeast, but there is a cluster of posts in East Africa as well. Ruddy Roye works primarily in New York City, but also has a number of posts that seem to track along the Mississippi River. Each of these writers is from the United States, but there stories are international in nature.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;/Screen-Shot-2015-05-19-at-1.47.19-PM.png&quot;&gt;&lt;img class=&quot; size-full wp-image-434 aligncenter&quot; src=&quot;/assets/Screen-Shot-2015-05-19-at-1.47.19-PM.png&quot; alt=&quot;Screen Shot 2015-05-19 at 1.47.19 PM&quot; width=&quot;775&quot; height=&quot;391&quot; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Finally, one benefit of gathering posts directly from Instagram is that in addition to the metadata I had included in my mostly manually gathered initial database, I now have more information I can work with including comments and “likes” for each post. This data allows me to visualize the popularity of each writer working in the genre (figure 6).&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;/Screen-Shot-2015-05-19-at-1.47.28-PM.png&quot;&gt;&lt;img class=&quot; size-full wp-image-433 aligncenter&quot; src=&quot;/assets/Screen-Shot-2015-05-19-at-1.47.28-PM.png&quot; alt=&quot;Screen Shot 2015-05-19 at 1.47.28 PM&quot; width=&quot;422&quot; height=&quot;624&quot; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Clearly, Neil Shea has amassed the most likes on his posts—even considering the fact that he has been at this longer—with Ruddy Roye relatively not far behind. The next most popular is Jeff Sharlet, Dan Schwartz, and then Randy Potts (thephatic).&lt;/p&gt;
&lt;p&gt;&lt;b&gt;6. Seeking New Writers: Principle Component Analysis and Classifying &lt;/b&gt;&lt;/p&gt;
&lt;p&gt;While it is interesting to perform this kind of analysis on the data I had collected, I have been aware throughout the process that these posts represent only a fraction of potential InstaEssays on Instagram. It is unclear just how big a fraction this is—I have no doubt that Jeff Sharlet and Neil Shea, in particular, represent the core of InstaEssay writers—but my goal is to present a more comprehensive picture of the genre. In order to accomplish this goal, I needed to know a number of things about the posts I had already collected. For example, is there something distinctive about the genre that could be detected by analyzing the texts of the posts in my database? To begin to answer this question I turned to Principle Component Analysis (PCA). Matthew Jockers, in his book &lt;i&gt;Macroanalysis&lt;/i&gt;, defines PCA as “a method of condensing multiple features into ‘principle components,’ components that represent, somewhat closely, but not perfectly, the amount of variance in the data.”&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;/Screen-Shot-2015-05-19-at-1.47.38-PM.png&quot;&gt;&lt;img class=&quot; size-full wp-image-432 aligncenter&quot; src=&quot;/assets/Screen-Shot-2015-05-19-at-1.47.38-PM.png&quot; alt=&quot;Screen Shot 2015-05-19 at 1.47.38 PM&quot; width=&quot;708&quot; height=&quot;504&quot; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Performing PCA on the posts by the authors I knew to be working in the genre showed that while there are some variations, particularly in the work of Neil Shea and Ruddy Roye, most posts do cluster together.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;/Screen-Shot-2015-05-19-at-1.47.52-PM.png&quot;&gt;&lt;img class=&quot; size-full wp-image-431 aligncenter&quot; src=&quot;/assets/Screen-Shot-2015-05-19-at-1.47.52-PM.png&quot; alt=&quot;Screen Shot 2015-05-19 at 1.47.52 PM&quot; width=&quot;570&quot; height=&quot;754&quot; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Figure 7 represents the top two principle components, PC1 and PC2. After seeing this, I wondered what I might learn from seeing PC1 charted over time. Figure 8 resulted, and helped me understand a bit better what the outliers might mean.&lt;/p&gt;
&lt;p&gt;There are a couple interesting things to note here. The first is that when PC2 is removed, the variation associated with Ruddy Roye disappears, which is to be expected since figure 7 shows that his variation existed in PC2. But, even more interesting is the way that, over time, Neil Shea’s posts begin to conform to the rest. In looking into this more closely, it turns out—as noted before—that initially Shea was reporting from East Africa and much of what distinguishes his earlier posts from the later ones is actually the content. All in all, visualizing the data in this way gave me the sense that perhaps there are enough commonalities in the InstaEssays I had collected to be able to expand my reach based on these posts.&lt;/p&gt;
&lt;p&gt;In order to accomplish this, I turned to classification, particularly a Naive Bayes classifier. This uses word frequencies to determine if a text belongs to one category or another. For my purposes, I created two categories. The first, based on the data I already knew to be InstaEssays, I simply labeled “Good.” Then, I collected all Instagram posts that use the hashtag #picturesandwords, which is commonly used in InstaEssays, but also in a lot of other, non-InstaEssay posts. These, I called “Unknown.” I ran the Naive Bayes classifier in an effort to determine if, based on my “Good” set, I could find other candidates for “Good” among the “Unknown.” To my great delight, it seems to have worked. This isn’t particularly easy to visualize, but when I created a new data frame to show only posts that had previously been part of the “Unknown” set and, based on Naive Bayes were predicted to be “Good,” I ended up with 51 posts, many of which (but not all) are indeed InstaEssays.&lt;/p&gt;
&lt;p&gt;In an effort to check my work, I created a visualization that would show the computer’s guesses in each category. Figure 9 shows that the vast majority of posts that I had labeled “Good” were also guessed to be “Good” by the classifier. And, of those I had determined to be  “Unknown,” a little less than half were deemed “Good.”&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;/Screen-Shot-2015-05-19-at-1.48.04-PM.png&quot;&gt;&lt;img class=&quot; size-full wp-image-430 aligncenter&quot; src=&quot;/assets/Screen-Shot-2015-05-19-at-1.48.04-PM.png&quot; alt=&quot;Screen Shot 2015-05-19 at 1.48.04 PM&quot; width=&quot;406&quot; height=&quot;567&quot; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;More so than directing me to individual posts for inclusion, however, this proved to be most helpful in identifying users that I might want to look into for inclusion in the archive. I created a new data frame that included only the names of users who had at least one post labeled as “Good,” and determined that there are 37 users that I should look at more closely. I can perform this same kind of classification on other commonly used hashtags and perhaps even on a wider set of Instagram posts.&lt;/p&gt;
&lt;p&gt;One final, and not particularly enlightening analysis I performed on the data that I had available was an attempt at topic modeling—a means of determining what these texts are about. Figure 10 shows the frequency of 8 “topics,” actually just groups of words, by username. With a bit of extrapolation, it does a fine job of indicating what each of the writers most often write about. For example, Jeff Sharlet wrote a long series of posts on a woman named Mary Mazur, and sure enough the topic most aligned with him includes the words “she,” “her,” “says,” and “mary.” Randy Potts (thephatic) reported on the recent protests in Ferguson, Missouri, and, as such, the topic that most aligns with him includes the words “police,” “ferguson,” and “breathe.”&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;/Screen-Shot-2015-05-19-at-1.48.12-PM.png&quot;&gt;&lt;img class=&quot; size-full wp-image-429 aligncenter&quot; src=&quot;/assets/Screen-Shot-2015-05-19-at-1.48.12-PM.png&quot; alt=&quot;Screen Shot 2015-05-19 at 1.48.12 PM&quot; width=&quot;702&quot; height=&quot;382&quot; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;b&gt;7. Where Do We Go From Here: Further Questions and Considerations&lt;/b&gt;&lt;/p&gt;
&lt;p&gt;As my main goal as an archivist of InstaEssays is to more efficiently and effectively gather relevant posts for inclusion in the archive, this process has proven quite successful. At the very least, being able to scrape Instagram for relevant posts and easily convert that data into a CSV for uploading to Omeka is a huge step in the right direction. Additionally, seeing as how to date there is still not a universally used hashtag that would indicate to me that a particular Instagram post is an InstaEssay, using classification to identify new posts and users for potential inclusion is extremely helpful.&lt;/p&gt;
&lt;p&gt;But even as I continue to gather data, new questions arise. Above I showed the ability to determine a user’s popularity on Instagram based on the number of likes his or her posts amassed. I would like to dig further into this data, however, to perhaps consider what, in particular, makes a post popular. This may be possible by gathering the most popular posts and using PCA to find their commonalities. Another approach may be to topic model this subset of posts to determine if particular topics are more popular.&lt;/p&gt;
&lt;p&gt;It is clear, at the end of this initial foray into working with R, that a combination of unsupervised analysis, like what I have detailed here, and more supervised analysis in which I comb through the results in an effort to determine the computer’s accuracy, is necessary. Additionally, I intend to streamline the process for scraping new posts from Instagram. Finally, a means of adding to my data frame without creating duplicates will be developed. At the start of this project, the problems I set out to solve included a method for more efficiently collecting InstaEssays, a means to find additional InstaEssays for inclusion from the vast sea of media that is Instagram, and assembling a set of tools for meaningful analysis of the data. While there is, of course, more to do, so far this has been a successful experiment.&lt;/p&gt;
</description>
        <pubDate>Tue, 19 May 2015 13:55:29 -0400</pubDate>
        <link>http://jonathandfitzgerald.com/blog/2015/05/19/the-instaessay-archive-past-present-and-future.html</link>
        <guid isPermaLink="true">http://jonathandfitzgerald.com/blog/2015/05/19/the-instaessay-archive-past-present-and-future.html</guid>
        
        
        <category>blog</category>
        
      </item>
    
      <item>
        <title>Re-Presenting Early Modern Pattern Poems as Material Objects</title>
        <description>&lt;p&gt;&lt;em&gt;The following is excerpted from a paper I gave at &lt;a href=&quot;http://emc.english.ucsb.edu/conferences/2014-2015/Making_program_TE.pdf&quot; target=&quot;_blank&quot;&gt;Making, Unmaking, and Remaking the Early Modern Era: 1500-1800, 14th Annual EMC Conference&lt;/a&gt; at UCSB in February. For this project, I used 3D printers and laser cutters to re-mediate Early Modern pattern poems as physical objects. For the TL;DR version, scroll down to the bottom to see pictures.&lt;/em&gt;&lt;/p&gt;
&lt;!--more--&gt;
&lt;p&gt;&lt;a href=&quot;/assets/Pattern-Poems-Presentation.0011.jpg&quot;&gt;&lt;img class=&quot;alignnone size-full wp-image-417&quot; src=&quot;/assets/Pattern-Poems-Presentation.0011.jpg&quot; alt=&quot;Pattern Poems Presentation.001&quot; width=&quot;1024&quot; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;I’m grateful for the opportunity to be here with you this weekend. I feel a bit like a fish out water — I’m not an Early Modernist. That seems like a confession that I need to make. I approached this project, rather as a Digital Humanist. I had the opportunity to study Early Modern Literature &amp;amp; Visual/Material Cultures with Professor Erika Boeckeler at Northeastern University, and it is was in that class that my interest in Early Modern pattern poetry and this project was born.&lt;/p&gt;
&lt;p&gt;Prior to the late 20th century, not much critical attention had been given to Early Modern pattern poems. Dick Higgins, who is certainly one of the most foremost scholars of pattern poetry notes in his essay “Pattern Poetry as Paradigm” that the genre has not been the subject of consistent study and when it has, he writes, it “was strongly under attack by almost all critics and observers” (“Pattern Poetry as Paradigm” 401). But, despite the persistent biases against pattern poetry (or visual poetry, shaped poetry, figured poetry), Higgins, writing in the late 1980s, saw a recent uptick in attention to genre and identified several potential reasons for this surge in interest, among them, the intermedial nature of pattern poetry. Indeed, it is through this characteristic of intermediality that I enter into the study of pattern poetry here — that is, the consideration of pattern poems as objects.&lt;/p&gt;
&lt;p&gt;There is of course a precedent for this kind of reading. Prior to the 17th century, pattern poetry was often actually inscribed on an object, thus taking its shape from the physical limitations of the object onto which the text was inscribed. But by the 17th century, pattern poetry separated from engraving on objects and moved to the page. In this rendering, Jeremy Adler writes, “the poem functions as object, a speaking artefact among other, silent objects” (141). How should this theory of poem as object inform our study of Early Modern pattern poetry? And, in what ways could we come to a better understanding of how pattern poems work (or don’t work) in light of contemporary theory and methods?&lt;/p&gt;
&lt;p&gt;Higgins frames a potential method for answering these questions in terms of a “double semiotic,” which, he notes, as of his writing, was lacking. This double semiotic would take into account “what the pieces and their images, whether visual or verbal, for instance, meant to the times from which the pieces emerge, and some common semiotic by which we could discuss what the pieces are to us, as indicators of all aspects of their meaning” (“Pattern Poetry as Paradigm” 403).&lt;/p&gt;
&lt;p&gt;In an effort to answer these questions, I set out to attempt to re-present several Early Modern pattern poems as objects in the most literal (and physical) sense. Using 3D printing technology, I created four poem/objects in an attempt to better understand their intermedial nature. What follows is an explanation of the theory underpinning my attempts at re-presenation, a discussion of the processes utilized, and a look at the results for three of the four poems.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Theory&lt;/b&gt;&lt;/p&gt;
&lt;p&gt;There is, particularly in the Digital Humanities, an increasing emphasis on the concept of making as a way of achieving greater understanding of a historical artifact, or more specifically for our purposes, a text.&lt;/p&gt;
&lt;p&gt;In her chapter of the “evolving anthology” &lt;i&gt;Literary Studies in the Digital Age&lt;/i&gt;, titled “Digital Scholarly Editing,” Susan Schreibman writes, “There are, of course, many shared goals between print editions and first-generation digital editions: above all, the creation of new works by means of a re-presentation of the works of the past” (Schreibman).&lt;/p&gt;
&lt;p&gt;In recent years, the idea of re-presenting has moved beyond creating digital versions of analog texts to include what Bethany Nowviskie calls “the fresh, full circuit of humanities computing.” That is, Nowviskie writes, “the loop from the physical to the digital to the material text and artifact again” (Nowviskie).&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Process&lt;/b&gt;&lt;/p&gt;
&lt;p&gt;In moving from theorizing to making, I experienced what Nowviskie — riffing off William Morris — calls “resistance in the materials” (Nowviskie). To put it another way, making 3D models of Early Modern pattern poems turned out to be a lot more difficult than I imagined. For each of the poems I chose for this project, I had a clear sense of what I wanted the physical object to look like when printed, but a far less clear notion as to how to make this vision a reality.&lt;/p&gt;
&lt;p&gt;The software I utilized includes SketchUp, a popular and rather simplistic program formerly owned by Google and now by Trimble; MeshLab, a 3D mesh processing program; Processing, a programming language and development environment that allowed me to run a script for turning an image into a height map; and Adobe Photoshop and Illustrator in which I modified and created images of the poems. With the exception of Photoshop, and to a lesser extent, Illustrator, I had never worked with any of these programs before and the learning curve was steep.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Results&lt;/b&gt;&lt;/p&gt;
&lt;p&gt;We’ll move now to a discussion of the poems themselves, beginning with George Herbert’s “Easter-Wings” and “The Altar.” These two pattern poems by George Herbert are perhaps the most well known of the genre, and as such, it seemed all but necessary to re-present them as objects. They each presented unique challenges as well as opportunities.&lt;/p&gt;
&lt;p&gt;For “Easter Wings,” I chose to use Mario A. Di Cesare’s transcription of the Bodleian manuscript. Di Cesare strongly asserts in his critical introduction that “the two poems named &lt;i&gt;Easter-wings &lt;/i&gt;were written as separate individual poems” and “the two were placed horizontally, the indentations of the text pushing lines right-ward (more definitely in &lt;i&gt;W &lt;/i&gt;than &lt;i&gt;B&lt;/i&gt;). The visual effect is clearly that of birds flying &lt;i&gt;across&lt;/i&gt; the sky” (LVIII). This is as opposed to other early renderings of the poem, which take the two poems as one poem with two stanzas, and align the stanzas (poems) vertically.&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone size-full wp-image-413&quot; src=&quot;/assets/Pattern-Poems-Presentation.001.jpg&quot; alt=&quot;Pattern Poems Presentation.001&quot; width=&quot;1024&quot; /&gt;&lt;/p&gt;
&lt;p&gt;Taking a cue from the seventh line in the poem, “O let me rise,” I decided to attempt making a height map of the poem’s text so that the words would literally rise off of the page. This involved running a computer script called “Image to 3D Printable Heightmap/Lithophane,” created by Amanda Ghassaei, on the image. This script designates a greater height to darker areas of an image and lesser height to lighter areas. The intended effect would be that the text and page border, rendered in black, would rise off the plane of the white page.&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone size-full wp-image-402&quot; src=&quot;/assets/Pattern-Poems-Presentation.003.jpg&quot; alt=&quot;Pattern Poems Presentation.003&quot; width=&quot;1024&quot; /&gt;&lt;/p&gt;
&lt;p&gt;I scanned a page of Di Cesare’s transcription and attempted to run the script but found that the resolution of the scanned page was not high enough to create the intended effect. So, to overcome this challenge, I chose to recreate Di Cesare’s transcription using Adobe Photoshop. I used the scan as a base image, over which I retyped the poem’s text, being careful to match the font and spacing as closely to Di Cesare’s as possible, and I redrew the page borders that exist in the Bodelian manuscript as well as Di Cesare’s version.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;/assets/Pattern-Poems-Presentation.004.jpg&quot;&gt;&lt;img class=&quot;alignnone size-full wp-image-403&quot; src=&quot;/assets/Pattern-Poems-Presentation.004.jpg&quot; alt=&quot;Pattern Poems Presentation.004&quot; width=&quot;1024&quot; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The object that resulted is not perfect. Apparently, due to its flat and large size, it failed multiple times in the lower cost 3D printer as the base — or the page — would warp and then fail. The piece that resulted is at least structurally sound, but still not perfect.  You can get a sense of the original page, but it is not clear enough to read. Also, and for a reason I’m not entirely sure about, the wonderful people at the 3D studio chose to print it on red plastic.&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone size-full wp-image-404&quot; src=&quot;/assets/Pattern-Poems-Presentation.005.jpg&quot; alt=&quot;Pattern Poems Presentation.005&quot; width=&quot;1024&quot; /&gt;&lt;/p&gt;
&lt;p&gt;In working with Herbert’s “The Altar,” I chose a much more straightforward approach. Using a scan of Di Cesare’s transcription, I traced the outline of the lines in SketchUp and then used the scanned image as a texture on the surface of the object. My chief concern here was to illustrate the brokenness of the altar as described in the opening line of the poem, “A broken Altar, Lord, the servant reares.” This concern was animated by what I perceive as a misreading by many critics, including Paul Dyck, in his essay “Altar, Heart, Title-Page: The Image of Holy Reading,” in which he writes that “The Altar” has “long had a critical reputation as one of Herbert’s most puzzling poems, precisely because its shape and its words apparently contradict each other: the poem displays a symmetrical, perfected altar while narrating ‘a broken altar’” (541).&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;/assets/Pattern-Poems-Presentation.007.jpg&quot;&gt;&lt;img class=&quot;alignnone size-full wp-image-406&quot; src=&quot;/assets/Pattern-Poems-Presentation.007.jpg&quot; alt=&quot;Pattern Poems Presentation.007&quot; width=&quot;1024&quot; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;And, indeed, in my re-presentation of the poem, again, using Di Cesare’s transcription of the Bodleian manuscript, it is clear that the shape is anything but symmetrical and perfected. Rather, the altar seems to be symmetrical on the left side, but on the right side it is jagged and, in fact, broken. This difference is even more pronounced in the physical object that resulted, which was printed using a kind of powder plaster.&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone size-full wp-image-407&quot; src=&quot;/assets/Pattern-Poems-Presentation.008.jpg&quot; alt=&quot;Pattern Poems Presentation.008&quot; width=&quot;1024&quot; /&gt;&lt;/p&gt;
&lt;p&gt;And, finally, we’ll look at the Anonymous true lover’s knot. The idea that prompted this project was first conceived when I encountered the few examples of lover’s knots available in &lt;i&gt;Recreation for ingenious head-peeces, or, A pleasant grove for their wits to walk in of epigrams 700, epitaphs 200, fancies a number, fantasticks abundance,&lt;/i&gt; edited by Sir John Mennes and James Smith and published in 1654. I was particularly drawn to the poem that begins (if indeed a beginning can be determined) “TRUE love is a pretious pleasure” because its text and shape so precisely align. Throughout the poem, love is likened to a wreath, a maze that entwines “two faire mindes,” a knot, and two hands grasping. Additionally, the text brings to the reader’s attention the novelty of the shape in noting the “pretious pleasure” of reading such a poem and the way the shape seduces the eye.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;/assets/Pattern-Poems-Presentation.009.jpg&quot;&gt;&lt;img class=&quot;alignnone size-full wp-image-408&quot; src=&quot;/assets/Pattern-Poems-Presentation.009.jpg&quot; alt=&quot;Pattern Poems Presentation.009&quot; width=&quot;1024&quot; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Part of the challenge of reading such a poem on the page — and to a much greater extent, reading it in digital facsimile most readily available at EEBO — is the necessity of rotating the page in order to follow the verse. This challenge, combined with my sense that lover’s knots, even more so than other pattern poems, mimic a shape — presumably rope or ribbon tied around itself — prompted me to want to create a version that could be more easily held and rotated to be read.&lt;/p&gt;
&lt;p&gt;With the insight and assistance of the staff at Northeastern’s 3D Printing Studio, I decided to use the Studio’s laser cutter to cut the poem into an object, in this case plywood, rather than build it from scratch. This option was available for the lover’s knot due to its more strictly mimetic quality — namely that the text is bordered by lines meant to represent rope or ribbon. The result is a stunning piece that is indeed easier to read and quite pleasurable in the act of rotating and following the thread, so to speak.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;/assets/Pattern-Poems-Presentation.010.jpg&quot;&gt;&lt;img class=&quot;alignnone size-full wp-image-409&quot; src=&quot;/assets/Pattern-Poems-Presentation.010.jpg&quot; alt=&quot;Pattern Poems Presentation.010&quot; width=&quot;1024&quot; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Though I only had the time here to discuss three of the poems I worked with, I did bring the other as well, Nathanael Richards’ “Key of Heaven,” and I’d be happy to share these with anyone who might be interested in getting a closer look.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;/assets/Pattern-Poems-Presentation.011.jpg&quot;&gt;&lt;img class=&quot;alignnone size-full wp-image-410&quot; src=&quot;/assets/Pattern-Poems-Presentation.011.jpg&quot; alt=&quot;Pattern Poems Presentation.011&quot; width=&quot;1024&quot; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Conclusion&lt;/b&gt;&lt;/p&gt;
&lt;p&gt;In her blog post — adapted from a talk she gave at the Geographies of Desire conference in 2012 — Sarah Werner considers “How might we use digital tools to look at texts differently” (Werner). She asks a further question that she then answers with a variety of examples of innovative ways to consider texts, “Can we move away from reading text to studying the physical characteristics of text, characteristics that can reveal important information about the content of the text and the cultural and historical creation of the artifact?” (Werner). Indeed, it is precisely this goal, to better understand the content, as well as the cultural and historical context of Early Modern pattern poetry that incited this project. Through the process of working closely with each poem, in varying instances recreating their texts, outlining their shapes, modeling them in 3D, and finally printing them, I believe we can come closer to understanding their intermedial nature and arrive nearer to that double semiotic that Dick Higgins suggested was key to understanding what he calls, “an unknown literature.”&lt;i&gt;&lt;br /&gt;
&lt;/i&gt;&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Works Cited&lt;/b&gt;&lt;/p&gt;
&lt;p&gt;Brown, C. C., and W. P. Ingoldsby. “George Herbert’s ’Easter-Wings.’” Huntington Library Quarterly 35.2 (1972): 131–142. JSTOR. Web. 12 Nov. 2014.&lt;/p&gt;
&lt;p&gt;Drucker, Johanna. “Un-Visual and Conceptual.” Open Letter 12.7 (2005): 117. Print.&lt;/p&gt;
&lt;p&gt;“Dyck on Herbert’s Shape Poems.pdf.” : n. pag. Print.&lt;/p&gt;
&lt;p&gt;Dyck, Paul. “Altar, Heart, Title-Page: The Image of Holy Reading [with Illustrations].” English Literary Renaissance 43.3 (2013): 541–571. Print.&lt;/p&gt;
&lt;p&gt;Grusin, Richard A. “Premediation.” Criticism 46.1 (2004): 17–39. Project MUSE. Web. 29 Nov. 2014.&lt;/p&gt;
&lt;p&gt;Herbert, George, and Bodleian Library. George Herbert The Temple: A Diplomatic Edition of the Bodleian Manuscript (Tanner 307). Binghamton, N.Y: Medieval &amp;amp; Renaissance Texts &amp;amp; Studies, 1995. Print. Medieval &amp;amp; Renaissance Texts &amp;amp; Studies v. 54.&lt;/p&gt;
&lt;p&gt;Higgins, Dick. “Pattern Poetry as Paradigm.” Poetics Today 10.2 (1989): 401–428. JSTOR. Web. 12 Nov. 2014.&lt;/p&gt;
&lt;p&gt;---. Pattern Poetry : Guide to an Unknown Literature. Albany: State University of New York Press, 1987. Print.&lt;/p&gt;
&lt;p&gt;Liu, Alan. “Imagining the New Media.” A companion to digital literary studies (2007): 1. Print.&lt;/p&gt;
&lt;p&gt;McLuhan, Marshall, and Lewis H. Lapham. Understanding Media: The Extensions of Man. Reprint edition. Cambridge, Mass: The MIT Press, 1994. Print.&lt;/p&gt;
&lt;p&gt;Mennes, John, Sir. Recreation for Ingenious Head-Peeces, Or, A Pleasant Grove for Their Wits to Walk in of Epigrams 700, Epitaphs 200, Fancies a Number, Fantasticks Abundance : With Their Addition, Multiplication, and Division. London : Printed by M. Simmons ..., 1654., 1654. Print. Early English Books, 1641-1700 / 1508:09.&lt;/p&gt;
&lt;p&gt;N., J. N. “Visual Poetry.” Poetry 31.6 (1928): 334–338. Print.&lt;/p&gt;
&lt;p&gt;Nowviskie, Bethany. “Resistance in the Materials.” Bethany Nowviskie. N.p., 4 Jan. 2013. Web. 14 Nov. 2014.&lt;/p&gt;
&lt;p&gt;Puttenham, George. Cornell Paperbacks : Art of English Poesy, A Critical Edition. Ithaca, NY, USA: Cornell University Press, 2007. ebrary. Web. 12 Nov. 2014.&lt;/p&gt;
&lt;p&gt;Ray, J.k. “Herbert’s Easter-Wings.” Explicator 49.3 (1991): 140. Print.&lt;/p&gt;
&lt;p&gt;Richards, Nathanael, ca. The Celestiall Publican A Sacred Poem: Liuely Describing the Birth, Progresse, Bloudy Passion, and Glorious Resurrection of Our Sauiour. The Spirituall Sea-Fight. The Mischieuous Deceites of the World, the Flesh, the Vicious Courtier. The Iesuite. The Diuell. Seauen Seuerall Poems, with Sundry Epitaphs and Anagrams. By Nathanael Richards Gent. London : Imprinted by Felix Kyngston, for Roger Michell, 1630., 1630. Print. Early English Books, 1475-1640 / 1079:03.&lt;/p&gt;
&lt;p&gt;Schreibman, Susan. “Digital Scholarly Editing.” Literary Studies in the Digital Age. Ed. Kenneth M. Price and Ray Siemens. Modern Language Association of America, 2013. CrossRef. Web. 4 Sept. 2014.&lt;/p&gt;
&lt;p&gt;Shaffer, E. S., ed. “Technopaigneia, Carmina Figurata and Bilder-Reime: Seventeenth-Century Figured Poetry in Historical Perspective.” Comparative Criticism: Volume 4, The Language of the Arts. Cambridge University Press, 1982. Print.&lt;/p&gt;
&lt;p&gt;Skelton, Robin. The Poetic Pattern. London, Routledge and Paul, 1956. Print.&lt;/p&gt;
&lt;p&gt;Summers, Joseph H. (Joseph Holmes). George Herbert : His Religion and Art. Binghamton, NY: Center for Medieval and Early Renaissance Studies, 1981. Print.&lt;/p&gt;
&lt;p&gt;Werner, Sarah. “Where Material Book Culture Meets Digital Humanities.” Wynken de Worde. N.p., 29 Apr. 2012. Web. 2 Dec. 2014.&lt;/p&gt;
&lt;p&gt;West, David. “Easter-Wings. (pattern Poem by George Herbert).” Notes and Queries 39.4 (1992): 448. Print.&lt;/p&gt;
&lt;p&gt;Wood, Chauncey. “Paradox and Imping in Herbert’s ’Easter-Wings.’” George Herbert Journal 32.1-2 (2008): 98+. Print.&lt;/p&gt;
</description>
        <pubDate>Tue, 05 May 2015 14:34:41 -0400</pubDate>
        <link>http://jonathandfitzgerald.com/blog/2015/05/05/re-presenting-early-modern-pattern-poems-as-material-objects.html</link>
        <guid isPermaLink="true">http://jonathandfitzgerald.com/blog/2015/05/05/re-presenting-early-modern-pattern-poems-as-material-objects.html</guid>
        
        
        <category>blog</category>
        
      </item>
    
      <item>
        <title>The Internet Will Not Save Us -- But Maybe it can Help Us Fix Peer-Review</title>
        <description>&lt;p&gt;There was a time when I thought the internet could save us all. It was probably somewhere in the middle of the 2000s. There was a sense then, as Web 2.0 emerged, that the great democratization of data had finally arrived and that by nature of everything being open and shareable and social and free, many of the problems we’d been saddled with because of traditional media would suddenly disappear.&lt;/p&gt;
&lt;!--more--&gt;
&lt;p&gt;I was thinking of these days of wonder while reading Kathleen Fitzpatrick’s &lt;i&gt;Planned Obsolescence&lt;/i&gt;, published in 2009. The book’s focus is the future of the academy, particularly in relation to emerging technologies. In the &lt;a href=&quot;http://mcpress.media-commons.org/plannedobsolescence/one/&quot;&gt;first chapter&lt;/a&gt;, Fitzpatrick takes on the problem of peer-review, which, she notes, is employed “in almost every aspect of the ways that we work, from hiring decisions through tenure and promotion reviews, in both internal and external grant and fellowship competitions, and, of course, in publishing.”&lt;/p&gt;
&lt;p&gt;Peer-review, Fitzpatrick notes, is a feature of “a closed system of discourse,” which stands in direct contrast to the very open and public nature of writing for the web, for example. It is propagated by the curmudgeonly stance of “the way things have always been done.” I have no doubt that there is room for change — and indeed improvement — in the system of peer-review, particularly as more and more academic journals make their way online, but I have some concerns about the way Fitzpatrick seems to put her faith in the already fading dream of Web 2.0 to bring about that change.&lt;/p&gt;
&lt;p&gt;The major shift, as Fitzpatrick sees it is, relates to positions of authority. In the old, peer-review model, authority is vested in traditional hierarchies within academia. But on the web, “the nature of authority is shifting, and shifting dramatically, in the era of the digital network.”&lt;/p&gt;
&lt;p&gt;As an example of the shifts that the internet has precipitated, Fitzpatrick notes the work of scholars in media studies who focus their work on “the extent to which, for instance, bloggers are decentralizing and may even be displacing the authority structures surrounding traditional journalism.” She goes on to cite other instances such as mash-ups, fan vids, and file sharing.&lt;/p&gt;
&lt;p&gt;The problem here, reading just five years after Fitzpatrick made these initial observations, is that her examples are dated in that they’ve either gone away, or have been proved wrong. Bloggers have not displaced the authority structures of traditional journalism. If there was any question that this prediction failed, the damage done by “citizen journalists” during the Boston Marathon bombings and the events that followed, in contrast to the excellent reporting by traditional media (The Boston Globe) should settle that debate.&lt;/p&gt;
&lt;p&gt;Beyond that, remember mash-ups? They had a brief, and highly theorized, moment in the spotlight. Mash-ups, as well as their cousins “fan vids,” turned out to be just not that interesting. And while the debate over content ownership and file sharing is nowhere near settled, it is clear we will never go back to the anarchic wild west of the web’s early days.&lt;/p&gt;
&lt;p&gt;The internet will not save us, after all. The “process of radical democratization in the Web 2.0 era” that Fitzpatrick observed in 2009 was already perched at the beginning of its decline. Some things changed, but mostly they just stayed the same.&lt;/p&gt;
&lt;p&gt;But, there is a bright spot ever on the horizon. That is, to cite Alan Liu’s idea about &lt;a href=&quot;http://www.jonathandfitzgerald.com/you-cant-go-home-again-wandering-the-new-media-wilderness/&quot;&gt;encounters&lt;/a&gt; with new media as occurring not across a border, but in a contact zone or “pagus,” we’re still wandering, still figuring things out. To that end, I like where Fitzpatrick goes toward the end of her chapter on Peer-Review. She writes, “we might all be better served by separating the question of credentialing from the publishing process, by allowing everything through the gate, and by designing a post-publication peer-review process that focuses on how a scholarly text should be received rather than whether it should be out there in the first place.”&lt;/p&gt;
&lt;p&gt;I like this idea of post-publication peer-review. Especially with work published online, editors and publishers are no longer constrained by financial or spatial commitments. So, they should feel more free to take risks, publish pieces they are unsure about, or perhaps even those they are sure won’t be popular, and let those pieces rise or fall based on the reactions of readers.&lt;/p&gt;
&lt;p&gt;But, even here, Fitzpatrick falls back into a little bit of Web 2.0 optimism. In discussing a peer-to-peer review system, in which the quality of reviews is measured in addition to that of the text itself, she suggests, “peer-review needs to be put not in the service of gatekeeping, or determining what should be published for any scholar to see, but of filtering, or determining what of the vast amount of material that has been published is of interest or value to a particular scholar.”&lt;/p&gt;
&lt;p&gt;Again, I like this idea of filtering over gatekeeping, but the overall idea rings with some of that mid-2000s optimism regarding the ability of the crowd to accurately determine what is of interest or value.  I think the solution may actually be somewhere in the space between the traditional authorities and the determining mob. The authorities are necessary, but perhaps not as gatekeepers, but indeed as filters. If this is modeled after anything, it is not the Web 2.0 dream of the previous decade, but the model of publishing as it exists today. That is, there are traditional publishing houses, smaller houses, academic presses, and self-publishers and they can all get a book out onto the market. Whether that book is any good or not is determined, typically, after it is published, by readers, critics, and award juries.&lt;/p&gt;
&lt;p&gt;Certainly this is not a perfect model either—marketing plays an oversized role in publishing and is generally contingent on the budget of the publisher, to identify one obvious flaw. But if the problem, as Fitzpatrick describes it, is a reductive system with outmoded metrics, making peer-review a post-publication process should help. This review, however, should not be left to the clicking masses, but to recognized scholars — shift the gatekeepers from their post at the gate to someplace just outside it. In a sense, this is what Fitzpatrick and her colleagues are trying to accomplish with the peer-to-peer review system, but it feels a bit too much like reducing the merits of scholars to Yelp reviews.&lt;/p&gt;
&lt;p&gt;At the end of Chapter One, Fitzpatrick returns us to a sense of what peer-review is supposed to have been, “part of an ongoing conversation among scholars.” It is clear that, even if at one time the traditional peer-review system functioned in just that way, it no longer does. Change is needed, but lasting change won’t come from jumping on the latest internet trend. Rather we should employ the long game, recognizing with Liu that we are in a contact zone in our journey to a new media, and as our perspective changes from within that zone, so, too, can our practices — including peer-review.&lt;/p&gt;
</description>
        <pubDate>Fri, 21 Nov 2014 14:39:55 -0500</pubDate>
        <link>http://jonathandfitzgerald.com/blog/2014/11/21/the-internet-will-not-save-us-but-maybe-it-can-help-us-fix-peer-review.html</link>
        <guid isPermaLink="true">http://jonathandfitzgerald.com/blog/2014/11/21/the-internet-will-not-save-us-but-maybe-it-can-help-us-fix-peer-review.html</guid>
        
        
        <category>blog</category>
        
      </item>
    
      <item>
        <title>Instagram Essay Introduction</title>
        <description>&lt;p&gt;In recent months, a number of writers and photographers have begun to utilize Instagram beyond its common use as an application that enables the creation, stylizing, and sharing of personal photographs to a particular group of friends and acquaintances, and rather as a journalistic tool. In particular, writers like Jeff Sharlet and photographers like Neil Shea have paired their photos with short narratives, constrained to 2200 characters by Instagram’s caption limit. The effect is similar to that of “Flash Fiction”—short, impactful self-contained stories—except that these stories are true and paired with a photograph of the subject.&lt;/p&gt;
&lt;!--more--&gt;
&lt;p&gt;The first example happens to be the first of this emerging genre that I encountered. It is from a series by Jeff Sharlet that he called #Nightshift. Sharlet is a writing professor at Dartmouth College and a journalist whose work has appeared in Rolling Stone, Harpers, GQ, and many others. He’s also an author of several books including &lt;i&gt;The Family&lt;/i&gt; and &lt;i&gt;Sweet Heaven When I Die. &lt;/i&gt;Sharlet started using Instagram to tell stories shortly after he joined (and after a few weeks of using it in the traditional way) by taking photos at an all-night Dunkin Donuts where he often goes to write. Typically, Instagram essays are not named—Instagram doesn’t have a place to title a picture—but Sharlet indicated that this is 4 of 4 of his #nightshift series.&lt;/p&gt;
&lt;h2&gt;Jeff Sharlet&#39;s #NightShift&lt;/h2&gt;
&lt;blockquote class=&quot;instagram-media&quot; style=&quot;background: #FFF; border: 0; border-radius: 3px; box-shadow: 0 0 1px 0 rgba(0,0,0,0.5),0 1px 10px 0 rgba(0,0,0,0.15); margin: 1px; max-width: 658px; padding: 0; width: calc(100% - 2px);&quot; data-instgrm-captioned=&quot;&quot; data-instgrm-version=&quot;3&quot;&gt;
&lt;div style=&quot;padding: 8px;&quot;&gt;
&lt;div style=&quot;background: #F8F8F8; line-height: 0; margin-top: 40px; padding: 50% 0; text-align: center; width: 100%;&quot;&gt;&lt;/div&gt;
&lt;p style=&quot;margin: 8px 0 0 0; padding: 0 4px;&quot;&gt;&lt;a style=&quot;color: #000; font-family: Arial,sans-serif; font-size: 14px; font-style: normal; font-weight: normal; line-height: 17px; text-decoration: none; word-wrap: break-word;&quot; href=&quot;https://instagram.com/p/tXfAShp377/&quot; target=&quot;_top&quot;&gt;Jasmine holds up her necklace. Number 10. “You can take a picture,” she says. Steve wraps his arm around her. His daughter? “No,” he says. Just, “no.” Jasmine poses. “She’s, uh, my friend,” he says. He used to be a baker here. Now he has a lawn business. Donuts were a transition. He used to be a trucker, too, and he drove a bus in Brooklyn, and he lived in Staten Island, where he’d lived his whole life, but then he got divorced, and—“my brother lives in Bradford.” Country life suits Steve. Can’t get used to the hours, though. He feels comfortable at night. “What brings you out ?” I ask. “Business,” he says. I don’t ask. “I’m a mother,” Jasmine says. She means that’s her job. She has a boy, 15-months-old, Joshua. “I named him for my cousin. He got killed in a car crash. In Queechee? He was in the service. That’s why I wear the number ten.” Steve squeezes her. Ten. The service? A football number? “That was the year he graduated,” she says. “He was a nice person.” Ten. “That’s my necklace! that’s my son!” Steve says, “You got your picture?” #photoessay 4 of 4, #nightshift #insomnia #countrylife #shesmyfriend #mother #truestories #blackandwhiteportrait&lt;/a&gt;&lt;/p&gt;
&lt;p style=&quot;font-family: Arial,sans-serif; color: #c9c8cd; font-size: 14px; line-height: 17px; margin-bottom: 0; margin-top: 8px; overflow: hidden; padding: 8px 0 7px; text-align: center; text-overflow: ellipsis; white-space: nowrap;&quot;&gt;A photo posted by Jeff Sharlet (@jeffsharlet) on &lt;time style=&quot;font-family: Arial,sans-serif; font-size: 14px; line-height: 17px;&quot; datetime=&quot;2014-09-25T11:33:13+00:00&quot;&gt;Sep 9, 2014 at 4:33am PDT&lt;/time&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;script src=&quot;//platform.instagram.com/en_US/embeds.js&quot; async=&quot;&quot; defer=&quot;defer&quot;&gt;&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;
&lt;p&gt;Sharlet began thinking about composing Instagram essays after seeing the work of Neil Shea, a National Geographic photographer who, just a few weeks before Sharlet, began using Instagram to share pictures and tell stories that weren’t going to make it into the magazine. This one is from a series he called #watershedstories and was taken in northern Kenya, along the border with Ethiopia.&lt;/p&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;
&lt;h2&gt;Neil Shea&#39;s #WatershedStories&lt;/h2&gt;
&lt;blockquote class=&quot;instagram-media&quot; style=&quot;background: #FFF; border: 0; border-radius: 3px; box-shadow: 0 0 1px 0 rgba(0,0,0,0.5),0 1px 10px 0 rgba(0,0,0,0.15); margin: 1px; max-width: 658px; padding: 0; width: calc(100% - 2px);&quot; data-instgrm-captioned=&quot;&quot; data-instgrm-version=&quot;3&quot;&gt;
&lt;div style=&quot;padding: 8px;&quot;&gt;
&lt;div style=&quot;background: #F8F8F8; line-height: 0; margin-top: 40px; padding: 50% 0; text-align: center; width: 100%;&quot;&gt;&lt;/div&gt;
&lt;p&gt;&lt;a style=&quot;color: #000; font-family: Arial,sans-serif; font-size: 14px; font-style: normal; font-weight: normal; line-height: 17px; text-decoration: none; word-wrap: break-word;&quot; href=&quot;https://instagram.com/p/uQg5Ljp9wn/&quot; target=&quot;_top&quot;&gt;You have some money, not much, a roll of small bills folded in your palm and marked with the faces of men and birds you have never seen. They’re worth only few dollars but that’s still something and you don’t like giving it away. You tuck a ball of tobacco behind your ear and stand watching while your sisters and cousins line up and lay gifts on a blanket before the men. They bring whatever they have, bracelets and earrings, knives, silver watches with blank irrelevant faces. One more ceremony in a stream that flows forever men-ward. Most days you don’t mind. You sit with your sisters in the shade making beer, feeding children, and teasing the men for wasting their time in gossip and sloth. Someone always tells the old joke of God’s first mistake and how He fixed it and everybody laughs. “Napuli!” Your aunt is calling. She sees your sharp elbow, your reluctant shoulders. “What are you waiting for? Give the boys some money.” The women singing now. Why does song come easy for them? How can they give so freely? “Napuli!” Yes, yes. You will. You just want to hold the bills a moment more. They are bright white, bank-crisp. Dry as leaves and whispering between your fingers. The problem is, you have been listening. Money tells a good story at night after the fires go out. The newlyweds, your neighbors, laugh and grunt in the darkness and you can hear them too through the stick walls but the money is louder. “Anything,” it has told you. “Anything.” And in the morning this story becomes the daydream. What you might do if you could keep it. #omoriver #kara #women #watershedstories #truestories #natgeo with @randyolson @thephotosociety @natgeo @natgeocreative&lt;/a&gt; A photo posted by Neil Shea (@neilshea13) on &lt;time style=&quot;font-family: Arial,sans-serif; font-size: 14px; line-height: 17px;&quot; datetime=&quot;2014-10-17T15:06:26+00:00&quot;&gt;Oct 10, 2014 at 8:06am PDT&lt;/time&gt;
&lt;/div&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;script src=&quot;//platform.instagram.com/en_US/embeds.js&quot; async=&quot;&quot; defer=&quot;defer&quot;&gt;&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;
&lt;p&gt;A number of other writers were inspired by Sharlet and Shea’s work, and began trying their hand at Instagram essays. This one is by a writer named Blair Braverman and tells the story of disposing of the bodies of dead sheep. Jeff Sharlet commented that it was his favorite Instagram essay.&lt;/p&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;
&lt;h2&gt;Blair Braverman 10/16&lt;/h2&gt;
&lt;blockquote class=&quot;instagram-media&quot; style=&quot;background: #FFF; border: 0; border-radius: 3px; box-shadow: 0 0 1px 0 rgba(0,0,0,0.5),0 1px 10px 0 rgba(0,0,0,0.15); margin: 1px; max-width: 658px; padding: 0; width: calc(100% - 2px);&quot; data-instgrm-captioned=&quot;&quot; data-instgrm-version=&quot;3&quot;&gt;
&lt;div style=&quot;padding: 8px;&quot;&gt;
&lt;div style=&quot;background: #F8F8F8; line-height: 0; margin-top: 40px; padding: 50% 0; text-align: center; width: 100%;&quot;&gt;&lt;/div&gt;
&lt;p style=&quot;margin: 8px 0 0 0; padding: 0 4px;&quot;&gt;&lt;a style=&quot;color: #000; font-family: Arial,sans-serif; font-size: 14px; font-style: normal; font-weight: normal; line-height: 17px; text-decoration: none; word-wrap: break-word;&quot; href=&quot;https://instagram.com/p/uOvumjFYw1/&quot; target=&quot;_top&quot;&gt;If we didn’t find the lambs fast enough, then the crows got them. The first time they beat us, they left a lamb with red holes for eyes stumbling in the mud, bawling for milk. There were live lambs everywhere, yellow and bloody, and this one seemed no more grotesque than any other. A killed it fast with the back of an axe while I waved my arms to distract its mother. // We&#39;d lost three ewes that week, birthing. The last one we got to in time to call a vet, and I held its neck while the man shoved loose, dangling organs back inside her. She didn&#39;t moan, just huffed her breath, her eyes wide and white and her head sinking ever lower. He threaded a shoelace under her tail, tied it in a bow, and said to untie it in a few days. She was bleeding like a faucet. It&#39;ll stop, he said, but it didn&#39;t, and the next morning the barn was full of crows that filled the air when I walked in, and smacked all at once against the windows, and the sheep was dead and her eyes gone too. A and I dragged her body out on a feed sack, heaving in unison. We had to heave twice over the door frame. &quot;Some people have cows,&quot; A said, panting, and we both laughed. // Two days later, another lamb, worse: its flesh and bone pecked out through a neat hole in its belly; its fleece still so clean and white. It was a bag of lamb, perfect but for its hollowness, and when A lifted it up I felt sick, the crows all around, watching. Even that morning, A had fed them bread behind the barn when no one was watching. It was his compulsion: he had to feed everything. Now he dropped the empty lamb into another empty sack. F leaned out the window with his father&#39;s rifle and shot twice, and nobody jumped but me. #TrueStories #NatureWriting #arctic #wordsandpictures #InstaEssay #farming #babyanimals&lt;/a&gt;&lt;/p&gt;
&lt;p style=&quot;font-family: Arial,sans-serif; color: #c9c8cd; font-size: 14px; line-height: 17px; margin-bottom: 0; margin-top: 8px; overflow: hidden; padding: 8px 0 7px; text-align: center; text-overflow: ellipsis; white-space: nowrap;&quot;&gt;A photo posted by Blair Braverman (@blair_braverman) on &lt;time style=&quot;font-family: Arial,sans-serif; font-size: 14px; line-height: 17px;&quot; datetime=&quot;2014-10-16T22:37:34+00:00&quot;&gt;Oct 10, 2014 at 3:37pm PDT&lt;/time&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;script src=&quot;//platform.instagram.com/en_US/embeds.js&quot; async=&quot;&quot; defer=&quot;defer&quot; type=&quot;mce-no/type&quot;&gt;&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;
&lt;p&gt;And one more, by Nicole Greenfield. I’m sharing this one because she directly attributes Sharlet as an inspiration for her “first go” at what she refers to both as “#wordsandpictures” and “#picturesandwords.”&lt;/p&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;
&lt;h2&gt;Nicole Greenfield #GreenPointStories&lt;/h2&gt;
&lt;blockquote class=&quot;instagram-media&quot; style=&quot;background: #FFF; border: 0; border-radius: 3px; box-shadow: 0 0 1px 0 rgba(0,0,0,0.5),0 1px 10px 0 rgba(0,0,0,0.15); margin: 1px; max-width: 658px; padding: 0; width: calc(100% - 2px);&quot; data-instgrm-captioned=&quot;&quot; data-instgrm-version=&quot;3&quot;&gt;
&lt;div style=&quot;padding: 8px;&quot;&gt;
&lt;div style=&quot;background: #F8F8F8; line-height: 0; margin-top: 40px; padding: 50% 0; text-align: center; width: 100%;&quot;&gt;&lt;/div&gt;
&lt;p&gt;&lt;a style=&quot;color: #000; font-family: Arial,sans-serif; font-size: 14px; font-style: normal; font-weight: normal; line-height: 17px; text-decoration: none; word-wrap: break-word;&quot; href=&quot;https://instagram.com/p/uV2aMKoFHJ/&quot; target=&quot;_top&quot;&gt;Inspired by @jeffsharlet, a first go at #wordsandpictures, #picturesandwords. // How you doing, honey? You play? Nope. You sing? Definitely not. You dance? Eh. Well you&#39;re just full of talents, aren&#39;t you? So it seems, I say. I&#39;m Joey, he says. // You live in Greenpoint? I tell him I do. I was born and raised here, Joey says, back when it was something. Now I don&#39;t get what&#39;s so great about it. All these kids moving here? Why? I point toward the river, suggesting the skyline view. Fuck that, he says. I had two huge rooms on Java Street. I was paying eight dollars and fifty cents. Two rooms, two huge rooms. When was that? 1959. Now you don&#39;t get shit. Imagine in my day I could take my girlfriend out. Two bucks. Go to a picture, have coffee and cake on the way out, buy cigarettes, and have forty cents left over, easy. And that&#39;s when I was splurgin&#39;. And down here, West Street, it was all industry. Everyone had a job. You lost your job, you had another in two days. Now it&#39;s all apartments, nothing here. I really don&#39;t get what&#39;s so great about this place anymore. // So what kind of music you into, honey? A bit of everything, I guess. What do you play? You like country? Cash? You know anything by Cash? How about Ring of Fire? Well, I don&#39;t do that cause I ain&#39;t got nobody to accompany me with it. I Walk the Line, he asks. Sure. &quot;I keep a close watch on this heart of mine...&quot; Joey sings the whole song for me, slowly, vowels long and drawn out. // Be good, honey, he tells me as I&#39;m leaving. And if you can&#39;t be good, don&#39;t get caught. #greenpoint #greenpointstories #truestories&lt;/a&gt; A photo posted by Nicole Greenfield (@nmgreenfield) on &lt;time style=&quot;font-family: Arial,sans-serif; font-size: 14px; line-height: 17px;&quot; datetime=&quot;2014-10-19T16:50:38+00:00&quot;&gt;Oct 10, 2014 at 9:50am PDT&lt;/time&gt;
&lt;/div&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;script src=&quot;//platform.instagram.com/en_US/embeds.js&quot; async=&quot;&quot; defer=&quot;defer&quot;&gt;&lt;/script&gt;&lt;/p&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;
&lt;p&gt;In recent weeks, media outlets have begun to pick up on this trend and locate it within the scope of literary journalism. The website “Longreads,” which typically syndicates long form reporting, &lt;a href=&quot;http://blog.longreads.com/2014/10/01/nightshift-excerpts-from-an-instagram-essay/&quot; target=&quot;_blank&quot;&gt;collected&lt;/a&gt; Sharlet’s #nightshift series and included an essay by Sharlet on the work. There he refers to Instagram essays as “Snapshot Journalism” and locates its lineage within the frame of comic books, which use words and pictures, and snapshots, which, he points out anyone can take.&lt;/p&gt;
&lt;p&gt;I’ll conclude with Jeff Sharlet’s conclusion from that essay. He writes, “It’s not the news. It’s not journalism in any conventional sense. It’s, Look at this! It’s, I saw these people, and I wanted you to see them, too.”&lt;/p&gt;
</description>
        <pubDate>Thu, 06 Nov 2014 22:06:22 -0500</pubDate>
        <link>http://jonathandfitzgerald.com/blog/2014/11/06/instagram-essay-presentation.html</link>
        <guid isPermaLink="true">http://jonathandfitzgerald.com/blog/2014/11/06/instagram-essay-presentation.html</guid>
        
        
        <category>blog</category>
        
      </item>
    
      <item>
        <title>Graphing with Gephi</title>
        <description>&lt;p&gt;The following PDF is a visual representation of my Facebook network. I completed this just after class last week as my first experiment with Gephi in an effort, simply, to get some data into the software and see what I could do with it. But, creating this graph had an additional benefit of showing me, in a way that I was having trouble imagining, the ways in which being able to graph a network can make things that may have been hidden, visible.&lt;/p&gt;
&lt;!--more--&gt;
&lt;p&gt;&lt;a href=&quot;/assets/Facebook.png&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;/assets/Facebook.png&quot; title=&quot;Facebook Network Graph&quot; height=&quot;500&quot; style=&quot;float:left;&quot;/&gt;&lt;/a&gt;In looking at the Facebook graph, for example, I was particularly interested in the outliers. There is a mass in the middle that represents my connections from college, many of which do in fact remain the most central in my life. But then, there are several adjacent networks that accurately mark different periods in my life—high school, for example, or my MA program, or the years I lived in Jersey City. Additionally, there are some smaller groups, or even single nodes, that each tell a story. I was particularly amused to find a distant connection, linked only through one friend, that reminded me of the disastrous weekend that my best friend visited with a new (and short lived) girlfriend. And yet, there she is, hanging precariously from the outer reaches of my network, connected by one thin edge.&lt;/p&gt;
&lt;p&gt;But though I found the Facebook graph helpful in getting to know Gephi, I knew that in order to fully immerse myself, I need to begin with data that I generated, import it, and go from there—in short, I needed to start from scratch.&lt;/p&gt;
&lt;p&gt;I spent a few days thinking about what might be valuable to visualize, and, particularly, I was thinking about how graphing might serve my final project. To that end, I imagined a graph that might show where the various contributors to The Paper, college students when they wrote, ended up publishing after college. Did they continue in the same vein of literary journalism? Did they continue in journalism at all? I still am interested in seeing this, but I have to wait until I have access to the data.&lt;/p&gt;
&lt;p&gt;In the meantime, I decided to try to accomplish something similar, using data I have available. For this, I turned to a couple of anthologies of literary journalism, &lt;i&gt;The Art of Fact&lt;/i&gt; and &lt;i&gt;Literary Journalism.&lt;/i&gt; I added each writer from both anthologies, as well as the name and date of the pieces that are collected. That was the easy part. From their, I turned to the “Permissions” section of each book and tried to determine where each piece was originally published. My sense was that, in doing this, I would be able to easily see which publications published the most literary journalism from the mid-twentieth century through today.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;/assets/Litjo.png&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;/assets/Litjo.png&quot; title=&quot;Facebook Network Graph&quot; height=&quot;500&quot; style=&quot;float:left;&quot;/&gt;&lt;/a&gt;What I didn’t anticipate, particularly in the case of those selections from &lt;i&gt;The Art of Fact,&lt;/i&gt; is that most permissions referred to books by the author as opposed to periodicals. My sense is that, even in many of these instances, the piece was originally published in a periodical before being collected into a collection of the author’s work, but I didn’t attempt to prove that for this exercise.&lt;/p&gt;
&lt;p&gt;Instead, what you see here, is a graph of mostly disconnected nodes. That is, with the exception of a few periodicals—The New Yorker and Esquire are the most notable—the relationships exist only between a single author and a single periodical or book. Ultimately, this doesn’t make for a very interesting graph, but it did prove an important exercise in that it helped me understand the opportunities, as well as the limitations, of graphing, and how both of those really depend on the data I’m working with.&lt;/p&gt;
</description>
        <pubDate>Thu, 06 Nov 2014 09:44:16 -0500</pubDate>
        <link>http://jonathandfitzgerald.com/blog/2014/11/06/graphing-with-gephi.html</link>
        <guid isPermaLink="true">http://jonathandfitzgerald.com/blog/2014/11/06/graphing-with-gephi.html</guid>
        
        
        <category>blog</category>
        
      </item>
    
  </channel>
</rss>
